import datetime as dt
import hashlib
import io
import json
import random
import re
import time
import zipfile
from dataclasses import dataclass
from pathlib import Path
from string import Template
from typing import TYPE_CHECKING, Callable, Dict, List, Optional, Set, Tuple
from urllib.parse import quote_plus

import numpy as np
import pandas as pd
import streamlit as st
from streamlit.components.v1 import html
from rapidfuzz import fuzz
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy import (JSON, Column, Date, DateTime, Float, Integer, MetaData,
                        String, Table, UniqueConstraint, create_engine, func,
                        select, tuple_)
from sqlalchemy import inspect
from sqlalchemy.engine import Engine
from sqlalchemy.exc import IntegrityError
from sqlalchemy.dialects.sqlite import insert as sqlite_insert
from sqlalchemy.sql import insert as sa_insert, text, update

DATA_DIR = Path("data")
DB_PATH = DATA_DIR / "takken.db"
UPLOAD_DIR = DATA_DIR / "uploads"
REJECT_DIR = DATA_DIR / "rejects"
OFFLINE_EXPORT_DIR = DATA_DIR / "offline_exports"
MAPPING_KIND_QUESTIONS = "questions"
MAPPING_KIND_ANSWERS = "answers"
DEFAULT_CATEGORY_MAP = {
    "å®…å»ºæ¥­æ³•": "å®…å»ºæ¥­æ³•",
    "æ¥­æ³•": "å®…å»ºæ¥­æ³•",
    "æ¨©åˆ©é–¢ä¿‚": "æ¨©åˆ©é–¢ä¿‚",
    "æ°‘æ³•": "æ¨©åˆ©é–¢ä¿‚",
    "æ³•ä»¤ä¸Šã®åˆ¶é™": "æ³•ä»¤ä¸Šã®åˆ¶é™",
    "åˆ¶é™": "æ³•ä»¤ä¸Šã®åˆ¶é™",
    "ç¨ãƒ»ãã®ä»–": "ç¨ãƒ»ãã®ä»–",
    "ç¨ãã®ä»–": "ç¨ãƒ»ãã®ä»–",
}
CATEGORY_CHOICES = ["å®…å»ºæ¥­æ³•", "æ¨©åˆ©é–¢ä¿‚", "æ³•ä»¤ä¸Šã®åˆ¶é™", "ç¨ãƒ»ãã®ä»–"]
DIFFICULTY_DEFAULT = 3
LAW_BASELINE_LABEL = "é©ç”¨æ³•ä»¤åŸºæº–æ—¥ï¼ˆR6/4/1ï¼‰"
LAW_REFERENCE_BASE_URL = "https://elaws.e-gov.go.jp/search?q={query}"

GLOBAL_SEARCH_SUGGESTIONS = [
    "é‡è¦äº‹é …èª¬æ˜",
    "æŠµå½“æ¨©",
    "éƒ½å¸‚è¨ˆç”»æ³•",
    "å®…å»ºæ¥­å…è¨±",
    "å®…åœ°å»ºç‰©å–å¼•å£«",
    "ç‘•ç–µæ‹…ä¿",
]

FONT_SIZE_SCALE = {
    "ã‚„ã‚„å°ã•ã„": 0.95,
    "æ¨™æº–": 1.0,
    "ã‚„ã‚„å¤§ãã„": 1.1,
    "å¤§ãã„": 1.2,
}

SUBJECT_PRESETS = {
    "ãƒãƒ©ãƒ³ã‚¹ã‚ˆã10å•": {
        "categories": CATEGORY_CHOICES,
        "difficulty": (1, 5),
        "review_only": False,
        "topics": [],
    },
    "æ°‘æ³•ãƒ»æ¨©åˆ©é–¢ä¿‚ã‚’é›†ä¸­æ¼”ç¿’": {
        "categories": ["æ¨©åˆ©é–¢ä¿‚"],
        "difficulty": (2, 5),
        "review_only": False,
        "topics": [],
    },
    "å¼±ç‚¹å¾©ç¿’ã«é›†ä¸­": {
        "categories": CATEGORY_CHOICES,
        "difficulty": (1, 4),
        "review_only": True,
        "topics": [],
    },
}

metadata = MetaData()

questions_table = Table(
    "questions",
    metadata,
    Column("id", String, primary_key=True),
    Column("year", Integer, nullable=False),
    Column("q_no", Integer, nullable=False),
    Column("category", String, nullable=False),
    Column("topic", String),
    Column("question", String, nullable=False),
    Column("choice1", String, nullable=False),
    Column("choice2", String, nullable=False),
    Column("choice3", String, nullable=False),
    Column("choice4", String, nullable=False),
    Column("correct", Integer),
    Column("explanation", String),
    Column("difficulty", Integer, default=DIFFICULTY_DEFAULT),
    Column("tags", String),
    Column("dup_note", String),
    UniqueConstraint("year", "q_no", name="uq_questions_year_qno"),
)

attempts_table = Table(
    "attempts",
    metadata,
    Column("id", Integer, primary_key=True, autoincrement=True),
    Column("question_id", String, nullable=False),
    Column("selected", Integer),
    Column("is_correct", Integer),
    Column("seconds", Integer),
    Column("mode", String),
    Column("exam_id", Integer),
    Column("confidence", Integer),
    Column("grade", Integer),
    Column("created_at", DateTime, server_default=func.now()),
)

exams_table = Table(
    "exams",
    metadata,
    Column("id", Integer, primary_key=True, autoincrement=True),
    Column("name", String),
    Column("started_at", DateTime),
    Column("finished_at", DateTime),
    Column("year_mode", String),
    Column("score", Integer),
)

srs_table = Table(
    "questions_srs",
    metadata,
    Column("question_id", String, primary_key=True),
    Column("repetition", Integer, default=0),
    Column("interval", Integer, default=1),
    Column("ease", Float, default=2.5),
    Column("due_date", Date),
    Column("last_grade", Integer),
    Column("updated_at", DateTime, server_default=func.now(), onupdate=func.now()),
)

import_logs_table = Table(
    "import_logs",
    metadata,
    Column("id", Integer, primary_key=True, autoincrement=True),
    Column("started_at", DateTime),
    Column("finished_at", DateTime),
    Column("files", Integer),
    Column("inserted", Integer),
    Column("updated", Integer),
    Column("rejected", Integer),
    Column("conflicts", Integer),
    Column("seconds", Float),
    Column("policy", String),
)

mapping_profiles_table = Table(
    "mapping_profiles",
    metadata,
    Column("id", Integer, primary_key=True, autoincrement=True),
    Column("name", String, nullable=False),
    Column("kind", String, nullable=False),
    Column("mapping_json", JSON, nullable=False),
    Column("created_at", DateTime, server_default=func.now()),
)

if TYPE_CHECKING:
    from streamlit.runtime.uploaded_file_manager import UploadedFile


def ensure_directories() -> None:
    DATA_DIR.mkdir(exist_ok=True)
    UPLOAD_DIR.mkdir(exist_ok=True)
    REJECT_DIR.mkdir(exist_ok=True)
    OFFLINE_EXPORT_DIR.mkdir(exist_ok=True)


def inject_style(css: str, style_id: str) -> None:
    sanitized_css = css.strip()
    if not sanitized_css:
        return
    css_payload = json.dumps(sanitized_css)
    style_id_payload = json.dumps(style_id)
    script = Template(
        """
        <script>
        (function() {
            const css = $css;
            const styleId = $style_id;
            const doc = window.parent ? window.parent.document : document;
            let styleTag = doc.getElementById(styleId);
            if (!styleTag) {
                styleTag = doc.createElement('style');
                styleTag.id = styleId;
                doc.head.appendChild(styleTag);
            }
            styleTag.innerHTML = css;
        })();
        </script>
        """
    ).substitute(css=css_payload, style_id=style_id_payload)
    html(script, height=0)


def ensure_schema_migrations(engine: Engine) -> None:
    inspector = inspect(engine)
    with engine.begin() as conn:
        attempt_columns = {col["name"] for col in inspector.get_columns("attempts")}
        if "confidence" not in attempt_columns:
            conn.execute(text("ALTER TABLE attempts ADD COLUMN confidence INTEGER"))
        if "grade" not in attempt_columns:
            conn.execute(text("ALTER TABLE attempts ADD COLUMN grade INTEGER"))


def apply_user_preferences() -> None:
    settings = st.session_state.get("settings", {})
    theme = settings.get("theme", "ãƒ©ã‚¤ãƒˆ")
    font_label = settings.get("font_size", "æ¨™æº–")
    scale = FONT_SIZE_SCALE.get(font_label, 1.0)
    base_css = f"""
:root {{
    --takken-font-scale: {scale};
}}
[data-testid="stAppViewContainer"] * {{
    font-size: calc(1rem * var(--takken-font-scale));
}}
.takken-search-suggestions .stButton>button {{
    width: 100%;
    margin-bottom: 0.35rem;
}}
.takken-search-suggestions .stButton>button:hover {{
    border-color: #6366f1;
}}
"""
    if theme == "ãƒ€ãƒ¼ã‚¯":
        theme_css = """
[data-testid="stAppViewContainer"] {
    background-color: #0e1117;
    color: #e7eefc;
}
[data-testid="stSidebar"] {
    background-color: #111827;
}
.stMetric, .stAlert {
    background-color: rgba(255, 255, 255, 0.04);
}
"""
    else:
        theme_css = """
[data-testid="stAppViewContainer"] {
    background-color: #f8fafc;
    color: #1f2933;
}
[data-testid="stSidebar"] {
    background-color: #ffffff;
}
"""
    inject_style(base_css + theme_css, "takken-theme-styles")


def build_search_dictionary(df: pd.DataFrame) -> List[str]:
    tokens: Set[str] = set(GLOBAL_SEARCH_SUGGESTIONS + CATEGORY_CHOICES)
    empty_series = pd.Series(dtype="object")
    tokens.update(str(cat).strip() for cat in df.get("category", empty_series).dropna())
    tokens.update(str(topic).strip() for topic in df.get("topic", empty_series).dropna())
    for tags in df.get("tags", empty_series).dropna():
        for token in re.split(r"[\s,;ã€/\\|]+", str(tags)):
            cleaned = token.strip()
            if len(cleaned) >= 2:
                tokens.add(cleaned)
    tokens = {token for token in tokens if token}
    return sorted(tokens)


def match_search_suggestions(dictionary: List[str], query: str, limit: int = 6) -> List[str]:
    if not dictionary:
        return []
    if not query:
        return dictionary[:limit]
    query_lower = query.lower()
    scored: List[Tuple[float, str]] = []
    for candidate in dictionary:
        candidate_lower = candidate.lower()
        score = fuzz.partial_ratio(query_lower, candidate_lower)
        if candidate_lower.startswith(query_lower):
            score += 20
        scored.append((score, candidate))
    scored.sort(key=lambda item: (-item[0], item[1]))
    filtered = [candidate for score, candidate in scored if score >= 30]
    if not filtered:
        filtered = [candidate for _, candidate in scored[:limit]]
    return filtered[:limit]


def trigger_global_search() -> None:
    query = str(st.session_state.get("global_search_input", "") or "").strip()
    st.session_state["global_search_query"] = query
    st.session_state["global_search_submitted"] = bool(query)


def clear_global_search() -> None:
    st.session_state["global_search_input"] = ""
    st.session_state["global_search_query"] = ""
    st.session_state["global_search_submitted"] = False
    st.session_state.pop("global_search_pending", None)


def request_clear_global_search() -> None:
    st.session_state["global_search_should_clear"] = True


def set_global_search_query(query: str) -> None:
    normalized = str(query or "").strip()
    st.session_state["global_search_pending"] = {
        "query": normalized,
        "submitted": bool(normalized),
    }
    st.session_state["global_search_query"] = normalized
    st.session_state["global_search_submitted"] = bool(normalized)


def safe_rerun() -> None:
    try:
        st.rerun()
    except AttributeError:
        st.experimental_rerun()


QUESTION_TEMPLATE_COLUMNS = [
    "year",
    "q_no",
    "category",
    "topic",
    "question",
    "choice1",
    "choice2",
    "choice3",
    "choice4",
    "explanation",
    "difficulty",
    "tags",
]

ANSWER_TEMPLATE_COLUMNS = [
    "year",
    "q_no",
    "correct_number",
    "correct_label",
    "correct_text",
    "explanation",
    "difficulty",
    "tags",
]


@st.cache_data(show_spinner=False)
def get_template_archive() -> bytes:
    question_template = pd.DataFrame(
        [
            {
                "year": dt.datetime.now().year,
                "q_no": 1,
                "category": CATEGORY_CHOICES[0],
                "topic": "å°åˆ†é¡ã®ä¾‹",
                "question": "ã“ã“ã«å•é¡Œæ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
                "choice1": "é¸æŠè‚¢1",
                "choice2": "é¸æŠè‚¢2",
                "choice3": "é¸æŠè‚¢3",
                "choice4": "é¸æŠè‚¢4",
                "explanation": "è§£èª¬ã‚’å…¥åŠ›ã§ãã¾ã™ã€‚",
                "difficulty": DIFFICULTY_DEFAULT,
                "tags": "ã‚¿ã‚°1;ã‚¿ã‚°2",
            }
        ],
        columns=QUESTION_TEMPLATE_COLUMNS,
    )
    answer_template = pd.DataFrame(
        [
            {
                "year": dt.datetime.now().year,
                "q_no": 1,
                "correct_number": 1,
                "correct_label": "A",
                "correct_text": "é¸æŠè‚¢1",
                "explanation": "æ­£ç­”ã®è§£èª¬ã‚’å…¥åŠ›ã§ãã¾ã™ã€‚",
                "difficulty": DIFFICULTY_DEFAULT,
                "tags": "ã‚¿ã‚°1;ã‚¿ã‚°2",
            }
        ],
        columns=ANSWER_TEMPLATE_COLUMNS,
    )
    buffer = io.BytesIO()
    with zipfile.ZipFile(buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        zf.writestr("questions_template.csv", question_template.to_csv(index=False))
        zf.writestr("answers_template.csv", answer_template.to_csv(index=False))
        q_excel = io.BytesIO()
        with pd.ExcelWriter(q_excel, engine="openpyxl") as writer:
            question_template.to_excel(writer, index=False, sheet_name="questions")
        zf.writestr("questions_template.xlsx", q_excel.getvalue())
        a_excel = io.BytesIO()
        with pd.ExcelWriter(a_excel, engine="openpyxl") as writer:
            answer_template.to_excel(writer, index=False, sheet_name="answers")
        zf.writestr("answers_template.xlsx", a_excel.getvalue())
        description = (
            "questions_template ã¯è¨­å•ãƒ‡ãƒ¼ã‚¿ã€answers_template ã¯æ­£ç­”ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚\n"
            "ä¸è¦ãªè¡Œã¯å‰Šé™¤ã—ã€ã”è‡ªèº«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã¦ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        )
        zf.writestr("README.txt", description)
    buffer.seek(0)
    return buffer.getvalue()


@st.cache_resource
def get_engine() -> Engine:
    ensure_directories()
    engine = create_engine(f"sqlite:///{DB_PATH}", future=True)
    metadata.create_all(engine)
    ensure_schema_migrations(engine)
    return engine


class DBManager:
    def __init__(self, engine: Engine) -> None:
        self.engine = engine

    def load_dataframe(self, table: Table) -> pd.DataFrame:
        with self.engine.connect() as conn:
            df = pd.read_sql(select(table), conn)
        return df

    def upsert_questions(self, df: pd.DataFrame) -> Tuple[int, int]:
        records = df.to_dict(orient="records")
        ids = [rec["id"] for rec in records if "id" in rec]
        year_qno_pairs = {
            (rec["year"], rec["q_no"]) for rec in records if "year" in rec and "q_no" in rec
        }
        inserted = 0
        updated = 0
        with self.engine.begin() as conn:
            if ids:
                existing_ids: Set[str] = set(
                    conn.execute(
                        select(questions_table.c.id).where(questions_table.c.id.in_(ids))
                    ).scalars()
                )
            else:
                existing_ids = set()

            if year_qno_pairs:
                existing_pairs = {
                    (row.year, row.q_no): row.id
                    for row in conn.execute(
                        select(
                            questions_table.c.year,
                            questions_table.c.q_no,
                            questions_table.c.id,
                        ).where(
                            tuple_(questions_table.c.year, questions_table.c.q_no).in_(
                                list(year_qno_pairs)
                            )
                        )
                    )
                }
            else:
                existing_pairs = {}

            for rec in records:
                rec_id = rec.get("id")
                year_qno = (rec.get("year"), rec.get("q_no"))
                update_values = {k: v for k, v in rec.items() if k != "id"}

                if rec_id in existing_ids:
                    conn.execute(
                        update(questions_table)
                        .where(questions_table.c.id == rec_id)
                        .values(**update_values)
                    )
                    updated += 1
                elif year_qno in existing_pairs:
                    existing_id = existing_pairs[year_qno]
                    conn.execute(
                        update(questions_table)
                        .where(questions_table.c.id == existing_id)
                        .values(**update_values)
                    )
                    updated += 1
                else:
                    conn.execute(sa_insert(questions_table).values(**rec))
                    inserted += 1
                    if rec_id:
                        existing_ids.add(rec_id)
                    if None not in year_qno:
                        existing_pairs[year_qno] = rec_id
        return inserted, updated

    def fetch_question(self, question_id: str) -> Optional[pd.Series]:
        with self.engine.connect() as conn:
            df = pd.read_sql(select(questions_table).where(questions_table.c.id == question_id), conn)
        if df.empty:
            return None
        return df.iloc[0]

    def record_attempt(
        self,
        question_id: str,
        selected: Optional[int],
        is_correct: bool,
        seconds: int,
        mode: str,
        exam_id: Optional[int] = None,
        confidence: Optional[int] = None,
        grade: Optional[int] = None,
    ) -> None:
        with self.engine.begin() as conn:
            conn.execute(
                sa_insert(attempts_table).values(
                    question_id=question_id,
                    selected=selected,
                    is_correct=int(is_correct),
                    seconds=seconds,
                    mode=mode,
                    exam_id=exam_id,
                    confidence=confidence,
                    grade=grade,
                )
            )

    def fetch_srs(self, question_id: str) -> Optional[pd.Series]:
        with self.engine.connect() as conn:
            df = pd.read_sql(
                select(srs_table).where(srs_table.c.question_id == question_id),
                conn,
            )
        if df.empty:
            return None
        return df.iloc[0]

    def log_exam_result(self, payload: Dict[str, object]) -> Optional[int]:
        with self.engine.begin() as conn:
            result = conn.execute(sa_insert(exams_table).values(**payload))
            inserted = result.inserted_primary_key
        if inserted:
            return inserted[0]
        return None

    def update_question_fields(
        self,
        question_id: str,
        fields: Dict[str, Optional[str]],
    ) -> None:
        with self.engine.begin() as conn:
            conn.execute(
                update(questions_table)
                .where(questions_table.c.id == question_id)
                .values(**fields)
            )

    def get_attempt_stats(self) -> pd.DataFrame:
        with self.engine.connect() as conn:
            df = pd.read_sql(
                text(
                    """
                    SELECT
                        a.question_id,
                        q.category,
                        q.topic,
                        q.year,
                        a.is_correct,
                        a.created_at,
                        a.seconds,
                        a.selected,
                        a.mode,
                        a.confidence,
                        a.grade
                    FROM attempts a
                    JOIN questions q ON q.id = a.question_id
                    """
                ),
                conn,
            )
        return df

    def get_due_srs(self) -> pd.DataFrame:
        today = dt.date.today()
        with self.engine.connect() as conn:
            df = pd.read_sql(
                select(srs_table, questions_table.c.question, questions_table.c.category)
                .where(srs_table.c.question_id == questions_table.c.id)
                .where((srs_table.c.due_date <= today) | (srs_table.c.due_date.is_(None))),
                conn,
            )
        return df

    def upsert_srs(self, question_id: str, payload: Dict[str, Optional[str]]) -> None:
        with self.engine.begin() as conn:
            stmt = sqlite_insert(srs_table).values(question_id=question_id, **payload)
            do_update = stmt.on_conflict_do_update(
                index_elements=[srs_table.c.question_id],
                set_={key: getattr(stmt.excluded, key) for key in payload},
            )
            conn.execute(do_update)

    def log_import(self, payload: Dict[str, Optional[str]]) -> None:
        with self.engine.begin() as conn:
            conn.execute(sa_insert(import_logs_table).values(**payload))

    def save_mapping_profile(self, name: str, kind: str, mapping: Dict[str, str]) -> None:
        with self.engine.begin() as conn:
            conn.execute(
                sa_insert(mapping_profiles_table).values(
                    name=name,
                    kind=kind,
                    mapping_json=mapping,
                )
            )

    def fetch_mapping_profiles(self, kind: Optional[str] = None) -> pd.DataFrame:
        with self.engine.connect() as conn:
            stmt = select(mapping_profiles_table)
            if kind:
                stmt = stmt.where(mapping_profiles_table.c.kind == kind)
            df = pd.read_sql(stmt, conn)
        return df

    def initialize_from_csv(self) -> None:
        with self.engine.connect() as conn:
            existing = conn.execute(select(func.count()).select_from(questions_table)).scalar()
        if existing and existing > 0:
            return
        questions_path = DATA_DIR / "questions_sample.csv"
        answers_path = DATA_DIR / "answers_sample.csv"
        if not questions_path.exists() or not answers_path.exists():
            return
        df_q = pd.read_csv(questions_path)
        df_a = pd.read_csv(answers_path)
        df_q = normalize_questions(df_q)
        df_a = normalize_answers(df_a)
        merged, *_ = merge_questions_answers(df_q, df_a, policy={"explanation": "overwrite", "tags": "merge"})
        self.upsert_questions(merged)
        rebuild_tfidf_cache()


@st.cache_data(show_spinner=False)
def load_questions_df() -> pd.DataFrame:
    engine = get_engine()
    db = DBManager(engine)
    df = db.load_dataframe(questions_table)
    return df


@st.cache_resource
def get_vectorizer() -> TfidfVectorizer:
    return TfidfVectorizer(stop_words=None, max_features=5000)


def rebuild_tfidf_cache() -> None:
    load_questions_df.clear()
    get_vectorizer.clear()
    load_questions_df()


def get_question_texts(df: pd.DataFrame) -> pd.Series:
    return df["question"].fillna("") + "\n" + df["explanation"].fillna("")


def compute_similarity(target_id: str, top_n: int = 3) -> pd.DataFrame:
    df = load_questions_df()
    if df.empty or target_id not in df["id"].values:
        return pd.DataFrame()
    texts = get_question_texts(df)
    vectorizer = get_vectorizer()
    matrix = vectorizer.fit_transform(texts)
    index = df.index[df["id"] == target_id][0]
    target_vec = matrix[index]
    sims = cosine_similarity(target_vec, matrix).flatten()
    df = df.assign(similarity=sims)
    df = df[df["id"] != target_id].nlargest(top_n, "similarity")
    return df[["id", "year", "q_no", "category", "question", "similarity"]]


def normalize_questions(df: pd.DataFrame, mapping: Optional[Dict[str, str]] = None) -> pd.DataFrame:
    df = df.copy()
    if mapping:
        df = df.rename(columns=mapping)
    required_cols = [
        "year",
        "q_no",
        "question",
        "choice1",
        "choice2",
        "choice3",
        "choice4",
    ]
    for col in required_cols:
        if col not in df.columns:
            raise ValueError(f"å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {col}")
    df["year"] = df["year"].astype(int)
    df["q_no"] = df["q_no"].astype(int)
    df["category"] = df.get("category", "").fillna("").apply(normalize_category)
    df["category"] = df["category"].replace("", CATEGORY_CHOICES[0])
    df["topic"] = df.get("topic", "").fillna("")
    df["explanation"] = df.get("explanation", "").fillna("")
    df["difficulty"] = (
        df.get("difficulty")
        .fillna(DIFFICULTY_DEFAULT)
        .replace("", DIFFICULTY_DEFAULT)
        .astype(int)
    )
    df["tags"] = df.get("tags", "").fillna("")
    if "id" not in df.columns or df["id"].isna().any():
        df["id"] = df.apply(generate_question_id, axis=1)
    df = df.drop_duplicates(subset=["id"])
    df = df[
        [
            "id",
            "year",
            "q_no",
            "category",
            "topic",
            "question",
            "choice1",
            "choice2",
            "choice3",
            "choice4",
            "explanation",
            "difficulty",
            "tags",
        ]
    ]
    return df


def normalize_answers(df: pd.DataFrame, mapping: Optional[Dict[str, str]] = None) -> pd.DataFrame:
    df = df.copy()
    if mapping:
        df = df.rename(columns=mapping)
    if "year" not in df.columns or "q_no" not in df.columns:
        raise ValueError("year ã¨ q_no ã¯å¿…é ˆã§ã™")
    df["year"] = df["year"].astype(int)
    df["q_no"] = df["q_no"].astype(int)
    for col in ["explanation", "tags"]:
        if col in df.columns:
            df[col] = df[col].fillna("")
    return df


def validate_question_records(df: pd.DataFrame) -> List[str]:
    errors: List[str] = []
    required_cols = [
        "year",
        "q_no",
        "question",
        "choice1",
        "choice2",
        "choice3",
        "choice4",
    ]
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        errors.append(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing)}")
        return errors
    working = df.reset_index(drop=True)
    if "id" in working.columns:
        dup_ids = working[working["id"].notna() & working["id"].duplicated()]["id"].unique()
        if dup_ids.size > 0:
            errors.append(f"é‡è¤‡ã—ãŸIDãŒå­˜åœ¨ã—ã¾ã™: {', '.join(map(str, dup_ids[:5]))}")
    dup_keys = working.duplicated(subset=["year", "q_no"], keep=False)
    if dup_keys.any():
        duplicates = working.loc[dup_keys, ["year", "q_no"]].reset_index()
        sample = ", ".join(
            f"{row.year}å¹´å•{row.q_no} (è¡Œ{row['index'] + 2})" for _, row in duplicates.head(5).iterrows()
        )
        errors.append(f"å¹´åº¦ã¨å•ç•ªã®çµ„ã¿åˆã‚ã›ãŒé‡è¤‡ã—ã¦ã„ã¾ã™: {sample}")
    for row_number, row in enumerate(working.itertuples(index=False), start=2):
        year = getattr(row, "year", "?")
        q_no = getattr(row, "q_no", "?")
        label = f"{year}å¹´å•{q_no} (è¡Œ{row_number})"
        question_text = str(getattr(row, "question", ""))
        if not question_text.strip():
            errors.append(f"{label}ï¼šå•é¡Œæ–‡ãŒç©ºæ¬„ã§ã™ã€‚")
        choices = [str(getattr(row, f"choice{i}", "")).strip() for i in range(1, 5)]
        if any(choice == "" for choice in choices):
            errors.append(f"{label}ï¼šç©ºæ¬„ã®é¸æŠè‚¢ãŒã‚ã‚Šã¾ã™ã€‚")
        non_empty = [c for c in choices if c]
        if len(set(non_empty)) < len(non_empty):
            errors.append(f"{label}ï¼šé¸æŠè‚¢ãŒé‡è¤‡ã—ã¦ã„ã¾ã™ã€‚")
    return errors


def validate_answer_records(df: pd.DataFrame) -> List[str]:
    errors: List[str] = []
    required_cols = ["year", "q_no", "correct_number"]
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        errors.append(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing)}")
        return errors
    working = df.reset_index(drop=True)
    dup_keys = working.duplicated(subset=["year", "q_no"], keep=False)
    if dup_keys.any():
        duplicates = working.loc[dup_keys, ["year", "q_no"]].reset_index()
        sample = ", ".join(
            f"{row.year}å¹´å•{row.q_no} (è¡Œ{row['index'] + 2})" for _, row in duplicates.head(5).iterrows()
        )
        errors.append(f"å¹´åº¦ã¨å•ç•ªã®çµ„ã¿åˆã‚ã›ãŒé‡è¤‡ã—ã¦ã„ã¾ã™: {sample}")
    if working["correct_number"].isna().any():
        rows = (working["correct_number"].isna().to_numpy().nonzero()[0] + 2).tolist()
        rows_text = ", ".join(map(str, rows[:5]))
        errors.append(f"correct_number ã«ç©ºæ¬„ãŒã‚ã‚Šã¾ã™ (è¡Œ {rows_text})ã€‚")
    try:
        invalid = pd.to_numeric(working["correct_number"], errors="coerce")
    except Exception:
        invalid = pd.Series([np.nan] * len(working))
    out_of_range = working[(invalid < 1) | (invalid > 4) | invalid.isna()]
    if not out_of_range.empty:
        sample_rows = ", ".join(
            f"{row.year}å¹´å•{row.q_no} (è¡Œ{row['index'] + 2})"
            for _, row in out_of_range.reset_index().head(5).iterrows()
        )
        errors.append(f"correct_number ã¯1ã€œ4ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„: {sample_rows}")
    return errors


def build_answers_export(df: pd.DataFrame) -> pd.DataFrame:
    records: List[Dict[str, object]] = []
    for _, row in df.iterrows():
        correct_number = row.get("correct")
        if pd.isna(correct_number):
            correct_number = None
            correct_label = ""
            correct_text = ""
        else:
            correct_number = int(correct_number)
            correct_label = ["A", "B", "C", "D"][correct_number - 1]
            correct_text = str(row.get(f"choice{correct_number}", ""))
        records.append(
            {
                "year": row.get("year"),
                "q_no": row.get("q_no"),
                "correct_number": correct_number,
                "correct_label": correct_label,
                "correct_text": correct_text,
                "explanation": row.get("explanation", ""),
                "difficulty": row.get("difficulty"),
                "tags": row.get("tags", ""),
            }
        )
    return pd.DataFrame(records, columns=ANSWER_TEMPLATE_COLUMNS)


def build_sample_questions_csv() -> str:
    sample_rows = [
        {
            "year": 2023,
            "q_no": 1,
            "category": "å®…å»ºæ¥­æ³•",
            "topic": "å…è¨±",
            "question": "å®…åœ°å»ºç‰©å–å¼•æ¥­è€…ã®å…è¨±ã«ã¤ã„ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã‹ã€‚",
            "choice1": "å…è¨±æ¨©è€…ã¯å¿…ãšå›½åœŸäº¤é€šå¤§è‡£ã§ã‚ã‚‹ã€‚",
            "choice2": "æ³•äººãŒå…è¨±ã‚’å—ã‘ã‚‹å ´åˆã€å°‚ä»»å–å¼•å£«ã¯ä¸è¦ã§ã‚ã‚‹ã€‚",
            "choice3": "å…è¨±æ›¿ãˆã®éš›ã¯æ—§å…è¨±ã®æœ‰åŠ¹æœŸé–“ã‚’å¼•ãç¶™ã’ã‚‹ã€‚",
            "choice4": "çŸ¥äº‹å…è¨±æ¥­è€…ãŒäºŒä»¥ä¸Šã®éƒ½é“åºœçœŒã«äº‹å‹™æ‰€ã‚’è¨­ã‘ã‚‹ã¨ãã¯å¤§è‡£å…è¨±ãŒå¿…è¦ã§ã‚ã‚‹ã€‚",
            "explanation": "å®…å»ºæ¥­æ³•ä¸Šã€äºŒä»¥ä¸Šã®éƒ½é“åºœçœŒã«äº‹å‹™æ‰€ã‚’è¨­ã‘ã‚‹å ´åˆã¯å¤§è‡£å…è¨±ãŒå¿…è¦ã€‚",
            "difficulty": 3,
            "tags": "å®…å»ºæ¥­æ³•;å…è¨±",
        },
        {
            "year": 2023,
            "q_no": 2,
            "category": "æ¨©åˆ©é–¢ä¿‚",
            "topic": "ç‰©æ¨©å¤‰å‹•",
            "question": "ä¸å‹•ç”£ç‰©æ¨©å¤‰å‹•ã®å¯¾æŠ—è¦ä»¶ã«é–¢ã™ã‚‹è¨˜è¿°ã¨ã—ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã‹ã€‚",
            "choice1": "ä¸å‹•ç”£ã®è´ˆä¸ã¯å£é ­ã§ã‚‚ç¬¬ä¸‰è€…ã«å¯¾æŠ—ã§ãã‚‹ã€‚",
            "choice2": "æ‰€æœ‰æ¨©ç§»è»¢ç™»è¨˜ã‚’å‚™ãˆãªã‘ã‚Œã°ç¬¬ä¸‰è€…ã«å¯¾æŠ—ã§ããªã„ã€‚",
            "choice3": "ä»®ç™»è¨˜ã®ã¾ã¾ã§ã‚‚å¸¸ã«ç¬¬ä¸‰è€…ã«å„ªå…ˆã™ã‚‹ã€‚",
            "choice4": "åœ°ä¸Šæ¨©è¨­å®šã¯ç™»è¨˜ç°¿ã®è¨˜è¼‰ã‚’è¦ã—ãªã„ã€‚",
            "explanation": "ä¸å‹•ç”£ç‰©æ¨©å¤‰å‹•ã®å¯¾æŠ—è¦ä»¶ã¯åŸå‰‡ã¨ã—ã¦ç™»è¨˜ã§ã‚ã‚‹ã€‚",
            "difficulty": 2,
            "tags": "æ¨©åˆ©é–¢ä¿‚;ç‰©æ¨©å¤‰å‹•",
        },
    ]
    buffer = io.StringIO()
    pd.DataFrame(sample_rows, columns=QUESTION_TEMPLATE_COLUMNS).to_csv(buffer, index=False)
    return buffer.getvalue()


def build_sample_answers_csv() -> str:
    sample_rows = [
        {
            "year": 2023,
            "q_no": 1,
            "correct_number": 4,
            "correct_label": "D",
            "correct_text": "çŸ¥äº‹å…è¨±æ¥­è€…ãŒäºŒä»¥ä¸Šã®éƒ½é“åºœçœŒã«äº‹å‹™æ‰€ã‚’è¨­ã‘ã‚‹ã¨ãã¯å¤§è‡£å…è¨±ãŒå¿…è¦ã€‚",
            "explanation": "å®…å»ºæ¥­æ³•ã®å…è¨±åˆ¶åº¦ã«åŸºã¥ãã€è¤‡æ•°éƒ½é“åºœçœŒã§å–¶æ¥­ã™ã‚‹å ´åˆã¯å¤§è‡£å…è¨±ãŒå¿…è¦ã§ã™ã€‚",
            "difficulty": 3,
            "tags": "å®…å»ºæ¥­æ³•;å…è¨±",
        },
        {
            "year": 2023,
            "q_no": 2,
            "correct_number": 2,
            "correct_label": "B",
            "correct_text": "æ‰€æœ‰æ¨©ç§»è»¢ç™»è¨˜ã‚’å‚™ãˆãªã‘ã‚Œã°ç¬¬ä¸‰è€…ã«å¯¾æŠ—ã§ããªã„ã€‚",
            "explanation": "ä¸å‹•ç”£ç‰©æ¨©å¤‰å‹•ã®å¯¾æŠ—è¦ä»¶ã¯ç™»è¨˜ãŒåŸå‰‡ã§ã™ã€‚",
            "difficulty": 2,
            "tags": "æ¨©åˆ©é–¢ä¿‚;ç‰©æ¨©å¤‰å‹•",
        },
    ]
    buffer = io.StringIO()
    pd.DataFrame(sample_rows, columns=ANSWER_TEMPLATE_COLUMNS).to_csv(buffer, index=False)
    return buffer.getvalue()


def merge_questions_answers(
    questions: pd.DataFrame,
    answers: pd.DataFrame,
    policy: Dict[str, str],
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    merged = questions.copy()
    if "correct" not in merged.columns:
        merged["correct"] = np.nan
    rejects_q = []
    rejects_a = []

    answer_map = {}
    for _, row in answers.iterrows():
        key = (row["year"], row["q_no"])
        answer_map[key] = row

    def determine_correct(row: pd.Series, ans_row: Optional[pd.Series]) -> Tuple[Optional[int], Optional[str], Optional[str]]:
        if ans_row is None:
            return None, None, None
        correct_number = ans_row.get("correct_number")
        if pd.notna(correct_number):
            try:
                correct_number = int(correct_number)
                if correct_number in [1, 2, 3, 4]:
                    return correct_number, ans_row.get("explanation"), ans_row.get("tags")
            except ValueError:
                pass
        label = ans_row.get("correct_label")
        if pd.notna(label):
            label = str(label).strip().upper()
            mapping = {"ï¼¡": 1, "A": 1, "ï¼¢": 2, "B": 2, "ï¼£": 3, "C": 3, "ï¼¤": 4, "D": 4}
            if label in mapping:
                return mapping[label], ans_row.get("explanation"), ans_row.get("tags")
        text_answer = ans_row.get("correct_text")
        if pd.notna(text_answer) and text_answer:
            choices = [row.get(f"choice{i}", "") for i in range(1, 5)]
            for idx, choice in enumerate(choices, start=1):
                if str(choice).strip() == str(text_answer).strip():
                    return idx, ans_row.get("explanation"), ans_row.get("tags")
            ratios = [fuzz.ratio(str(choice), str(text_answer)) for choice in choices]
            max_ratio = max(ratios)
            if max_ratio >= 90:
                idx = ratios.index(max_ratio) + 1
                return idx, ans_row.get("explanation"), ans_row.get("tags")
            else:
                rejects_a.append({**ans_row.to_dict(), "reason": "é¸æŠè‚¢ã¨ä¸€è‡´ã›ãš"})
                return None, None, None
        rejects_a.append({**ans_row.to_dict(), "reason": "æ­£ç­”æƒ…å ±ãŒä¸è¶³"})
        return None, None, None

    conflicts = []
    for idx, row in merged.iterrows():
        key = (row["year"], row["q_no"])
        ans_row = answer_map.get(key)
        correct, exp_override, tags_new = determine_correct(row, ans_row)
        if correct is not None:
            if pd.notna(row.get("correct")) and row.get("correct") != correct:
                conflicts.append({
                    "id": row["id"],
                    "year": row["year"],
                    "q_no": row["q_no"],
                    "existing": row.get("correct"),
                    "incoming": correct,
                })
            merged.at[idx, "correct"] = correct
        if ans_row is not None:
            if policy.get("explanation", "overwrite") == "overwrite" and pd.notna(ans_row.get("explanation")):
                merged.at[idx, "explanation"] = ans_row.get("explanation")
            elif policy.get("explanation") == "append":
                merged.at[idx, "explanation"] = (str(row.get("explanation", "")) + "\n" + str(ans_row.get("explanation", ""))).strip()
            if tags_new:
                if policy.get("tags", "merge") == "merge" and row.get("tags"):
                    tags_combined = set(str(row.get("tags", "")).split(";")) | set(str(tags_new).split(";"))
                    merged.at[idx, "tags"] = ";".join(sorted({t.strip() for t in tags_combined if t.strip()}))
                else:
                    merged.at[idx, "tags"] = tags_new
            if pd.notna(ans_row.get("difficulty")):
                merged.at[idx, "difficulty"] = int(ans_row.get("difficulty"))
    merged["correct"] = merged["correct"].fillna(0).astype(int).replace(0, np.nan)
    rejects_q_df = pd.DataFrame(rejects_q)
    rejects_a_df = pd.DataFrame(rejects_a)
    conflicts_df = pd.DataFrame(conflicts)
    return merged, rejects_q_df, rejects_a_df, conflicts_df


def normalize_category(value: str) -> str:
    if not value:
        return CATEGORY_CHOICES[0]
    value = str(value).strip()
    if value in CATEGORY_CHOICES:
        return value
    for key, target in DEFAULT_CATEGORY_MAP.items():
        if key in value:
            return target
    scores = {cat: fuzz.partial_ratio(value, cat) for cat in CATEGORY_CHOICES}
    best_cat = max(scores, key=scores.get)
    if scores[best_cat] >= 70:
        return best_cat
    return CATEGORY_CHOICES[0]


def generate_question_id(row: pd.Series) -> str:
    base = f"{row['year']}|{row['q_no']}|{str(row['question'])[:80]}"
    return hashlib.sha256(base.encode("utf-8")).hexdigest()[:16]


@dataclass
class ExamSession:
    id: Optional[int]
    name: str
    questions: List[str]
    started_at: dt.datetime
    year_mode: str
    mode: str


@dataclass
class QuestionNavigation:
    has_prev: bool = False
    has_next: bool = False
    on_prev: Optional[Callable[[], None]] = None
    on_next: Optional[Callable[[], None]] = None
    label: Optional[str] = None


def select_random_questions(df: pd.DataFrame, count: int) -> List[str]:
    if df.empty:
        return []
    return random.sample(list(df["id"]), min(count, len(df)))


def stratified_exam(df: pd.DataFrame) -> List[str]:
    quotas = {"å®…å»ºæ¥­æ³•": 20, "æ¨©åˆ©é–¢ä¿‚": 14, "æ³•ä»¤ä¸Šã®åˆ¶é™": 8, "ç¨ãƒ»ãã®ä»–": 8}
    selected = []
    remaining = df.copy()
    for category, quota in quotas.items():
        subset = remaining[remaining["category"] == category]
        chosen = select_random_questions(subset, quota)
        selected.extend(chosen)
        remaining = remaining[~remaining["id"].isin(chosen)]
    if len(selected) < 50:
        additional = select_random_questions(remaining, 50 - len(selected))
        selected.extend(additional)
    return selected


def sm2_update(row: Optional[pd.Series], grade: int, initial_ease: float = 2.5) -> Dict[str, object]:
    today = dt.date.today()
    if row is None:
        repetition = 0
        interval = 1
        ease = initial_ease
    else:
        repetition = row.get("repetition", 0) or 0
        interval = row.get("interval", 1) or 1
        ease = row.get("ease", 2.5) or 2.5
    schedule = [1, 3, 7, 21]
    if grade >= 3:
        if repetition < len(schedule):
            interval = schedule[repetition]
        else:
            interval = int(round(max(interval, schedule[-1]) * ease))
        repetition += 1
    else:
        repetition = 0
        interval = 1
    ease = ease + (0.1 - (5 - grade) * (0.08 + (5 - grade) * 0.02))
    ease = max(ease, 1.3)
    due_date = today + dt.timedelta(days=interval)
    return {
        "repetition": repetition,
        "interval": interval,
        "ease": ease,
        "due_date": due_date,
        "last_grade": grade,
        "updated_at": dt.datetime.now(),
    }


def inject_ui_styles() -> None:
    if st.session_state.get("_ui_styles_injected"):
        return
    inject_style(
        """
.takken-choice-button button {
    width: 100%;
    min-height: 56px;
    font-size: 1.05rem;
    border-radius: 0.8rem;
}
.takken-choice-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
    gap: 0.75rem;
    margin-bottom: 0.5rem;
}
@media (max-width: 768px) {
    .takken-choice-grid {
        grid-template-columns: 1fr;
    }
}
.takken-inline-actions button {
    min-height: 48px;
}
""",
        "takken-ui-styles",
    )
    st.session_state["_ui_styles_injected"] = True


def confidence_to_grade(is_correct: bool, confidence: int) -> int:
    confidence = max(0, min(100, confidence))
    if is_correct:
        if confidence >= 90:
            return 5
        if confidence >= 70:
            return 4
        if confidence >= 50:
            return 3
        return 2
    if confidence >= 70:
        return 1
    return 0


def get_offline_attempts_df() -> pd.DataFrame:
    records = st.session_state.get("offline_attempts", [])
    if not records:
        return pd.DataFrame()
    return pd.DataFrame(records)


def persist_offline_attempts(df: pd.DataFrame) -> None:
    if df.empty:
        return
    OFFLINE_EXPORT_DIR.mkdir(exist_ok=True)
    csv_path = OFFLINE_EXPORT_DIR / "attempts_latest.csv"
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    parquet_path = OFFLINE_EXPORT_DIR / "attempts_latest.parquet"
    try:
        df.to_parquet(parquet_path, index=False)
        st.session_state["_offline_parquet_error"] = None
    except Exception as exc:
        st.session_state["_offline_parquet_error"] = str(exc)
        if parquet_path.exists():
            parquet_path.unlink()


def log_offline_attempt(entry: Dict[str, object]) -> None:
    attempts = st.session_state.setdefault("offline_attempts", [])
    attempts.append(entry)
    df = get_offline_attempts_df()
    persist_offline_attempts(df)


def render_offline_downloads(key_prefix: str) -> None:
    df = get_offline_attempts_df()
    if df.empty:
        return
    with st.expander("å­¦ç¿’çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", expanded=False):
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False)
        st.download_button(
            "CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_buffer.getvalue(),
            file_name="takken_learning_log.csv",
            mime="text/csv",
            key=f"{key_prefix}_csv",
        )
        parquet_buffer = io.BytesIO()
        parquet_error = st.session_state.get("_offline_parquet_error")
        if parquet_error:
            st.warning(f"Parquetã®è‡ªå‹•ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {parquet_error}")
        try:
            parquet_buffer.seek(0)
            df.to_parquet(parquet_buffer, index=False)
            st.download_button(
                "Parquetã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=parquet_buffer.getvalue(),
                file_name="takken_learning_log.parquet",
                mime="application/octet-stream",
                key=f"{key_prefix}_parquet",
            )
        except Exception as exc:
            st.warning(f"Parquetã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
        st.caption(f"ãƒ•ã‚¡ã‚¤ãƒ«ã¯ {OFFLINE_EXPORT_DIR.as_posix()} ã«ã‚‚è‡ªå‹•ä¿å­˜ã•ã‚Œã¾ã™ã€‚")


def build_snippet(text: str, keyword: str, width: int = 80) -> str:
    if not text:
        return ""
    pattern = re.compile(re.escape(keyword), re.IGNORECASE)
    match = pattern.search(text)
    cleaned = re.sub(r"\s+", " ", text)
    if not match:
        return (cleaned[:width] + "â€¦") if len(cleaned) > width else cleaned
    start = max(0, match.start() - width // 2)
    end = min(len(cleaned), match.end() + width // 2)
    snippet = cleaned[start:end]
    if start > 0:
        snippet = "â€¦" + snippet
    if end < len(cleaned):
        snippet = snippet + "â€¦"
    return snippet


def search_questions(df: pd.DataFrame, query: str) -> pd.DataFrame:
    keywords = [kw.strip() for kw in re.split(r"[\sã€€]+", query) if kw.strip()]
    if not keywords:
        return df.iloc[0:0]
    mask = pd.Series(True, index=df.index)
    choice_cols = [f"choice{i}" for i in range(1, 5)]
    for kw in keywords:
        pattern = re.escape(kw)
        col_mask = df["question"].fillna("").str.contains(pattern, case=False, na=False)
        col_mask |= df["topic"].fillna("").str.contains(pattern, case=False, na=False)
        col_mask |= df["tags"].fillna("").str.contains(pattern, case=False, na=False)
        for col in choice_cols:
            col_mask |= df[col].fillna("").str.contains(pattern, case=False, na=False)
        mask &= col_mask
    results = df[mask].copy()
    if results.empty:
        return results
    primary = keywords[0]
    results["snippet"] = results.apply(
        lambda row: build_snippet(
            "\n".join(
                [
                    str(row.get("question", "")),
                    *(str(row.get(f"choice{i}", "")) for i in range(1, 5)),
                    str(row.get("explanation", "")),
                ]
            ),
            primary,
        ),
        axis=1,
    )
    return results


def render_global_search_panel(db: DBManager, df: pd.DataFrame, query: str) -> None:
    st.markdown("## ğŸ” æ¨ªæ–­æ¤œç´¢çµæœ")
    results = search_questions(df, query)
    if results.empty:
        st.info("è©²å½“ã™ã‚‹å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
        return
    with st.expander("ä¸¦ã³æ›¿ãˆãƒ»ãƒ•ã‚£ãƒ«ã‚¿", expanded=False):
        category_options = sorted({str(cat) for cat in results["category"].dropna()})
        selected_categories = st.multiselect(
            "åˆ†é‡ã§çµã‚Šè¾¼ã¿",
            category_options,
            default=category_options,
            help="èˆˆå‘³ã®ã‚ã‚‹åˆ†é‡ã ã‘ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚",
            key="global_search_categories",
        )
        year_values = sorted({int(y) for y in results["year"].dropna().astype(int)})
        year_range: Optional[Tuple[int, int]]
        if year_values:
            min_year, max_year = year_values[0], year_values[-1]
            if min_year == max_year:
                st.caption(f"å¹´åº¦ãƒ•ã‚£ãƒ«ã‚¿: {min_year}å¹´ã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚")
                year_range = (min_year, max_year)
            else:
                year_range = st.slider(
                    "å¹´åº¦ç¯„å›²",
                    min_year,
                    max_year,
                    (min_year, max_year),
                    help="å­¦ç¿’ã—ãŸã„å¹´åº¦ã«çµã‚Šè¾¼ã‚ã¾ã™ã€‚",
                    key="global_search_year_range",
                )
        else:
            year_range = None
        snippet_keyword = st.text_input(
            "è¦ç´„å†…ãƒ•ã‚£ãƒ«ã‚¿",
            key="global_search_snippet_filter",
            help="è¦ç´„ã«å«ã¾ã‚Œã‚‹èªå¥ã§ã•ã‚‰ã«çµã‚Šè¾¼ã¿ã¾ã™ã€‚",
        )
        sort_option = st.selectbox(
            "ä¸¦ã³é †",
            ["é–¢é€£åº¦é †", "å¹´åº¦ (æ–°ã—ã„é †)", "å¹´åº¦ (å¤ã„é †)", "å•ç•ªæ˜‡é †"],
            help="æ¤œç´¢çµæœã®è¡¨ç¤ºé †åºã‚’å¤‰æ›´ã§ãã¾ã™ã€‚",
            key="global_search_sort",
        )
    filtered = results.copy()
    if selected_categories:
        filtered = filtered[filtered["category"].isin(selected_categories)]
    if year_range:
        filtered = filtered[filtered["year"].between(year_range[0], year_range[1])]
    if snippet_keyword:
        filtered = filtered[
            filtered["snippet"].str.contains(snippet_keyword, case=False, na=False)
            | filtered["question"].str.contains(snippet_keyword, case=False, na=False)
        ]
    if filtered.empty:
        st.info("æ¡ä»¶ã«åˆè‡´ã™ã‚‹çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç·©ã‚ã¦å†æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚")
        return
    if sort_option == "å¹´åº¦ (æ–°ã—ã„é †)":
        filtered = filtered.sort_values(["year", "q_no"], ascending=[False, True])
    elif sort_option == "å¹´åº¦ (å¤ã„é †)":
        filtered = filtered.sort_values(["year", "q_no"], ascending=[True, True])
    elif sort_option == "å•ç•ªæ˜‡é †":
        filtered = filtered.sort_values(["q_no", "year"], ascending=[True, False])
    else:
        filtered = filtered.sort_values(["year", "q_no"], ascending=[False, True])
    display = filtered.head(30)
    summary_df = display[
        ["year", "q_no", "category", "topic", "snippet", "id"]
    ].rename(
        columns={
            "year": "å¹´åº¦",
            "q_no": "å•ç•ª",
            "category": "åˆ†é‡",
            "topic": "å°åˆ†é¡",
            "snippet": "è¦ç´„",
            "id": "å•é¡ŒID",
        }
    )
    st.dataframe(
        summary_df.set_index("å•é¡ŒID"),
        use_container_width=True,
        column_config={
            "å¹´åº¦": st.column_config.NumberColumn("å¹´åº¦", format="%d", help="ã‚¯ãƒªãƒƒã‚¯ã§ä¸¦ã³æ›¿ãˆã§ãã¾ã™ã€‚"),
            "å•ç•ª": st.column_config.NumberColumn("å•ç•ª", format="%d", help="å•ç•ªå·ã§ã‚½ãƒ¼ãƒˆã§ãã¾ã™ã€‚"),
            "åˆ†é‡": st.column_config.TextColumn("åˆ†é‡", help="ã‚«ãƒ†ã‚´ãƒªåã«ãƒã‚¦ã‚¹ã‚ªãƒ¼ãƒãƒ¼ã™ã‚‹ã¨å…¨æ–‡ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"),
            "å°åˆ†é¡": st.column_config.TextColumn("å°åˆ†é¡", help="ç´°ç›®åˆ†é¡ã§ã®æ¤œç´¢ã«å½¹ç«‹ã¡ã¾ã™ã€‚"),
            "è¦ç´„": st.column_config.TextColumn("è¦ç´„", help="å•é¡Œæ–‡ã‚„è§£èª¬ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã—ãŸã‚µãƒãƒªãƒ¼ã§ã™ã€‚"),
        },
    )
    selected_id = st.selectbox(
        "æ¤œç´¢çµæœã‹ã‚‰å•é¡Œã‚’é–‹ã",
        display["id"],
        format_func=lambda x: format_question_label(df, x),
        key="global_search_select",
    )
    row = df[df["id"] == selected_id].iloc[0]
    render_question_interaction(db, row, attempt_mode="search", key_prefix="search")


def get_review_candidate_ids(db: DBManager) -> Set[str]:
    review_ids: Set[str] = set()
    attempts = db.get_attempt_stats()
    if not attempts.empty:
        attempts["created_at"] = pd.to_datetime(attempts["created_at"])
        last_attempts = (
            attempts.sort_values("created_at").groupby("question_id", as_index=False).tail(1)
        )
        review_ids.update(last_attempts[last_attempts["is_correct"] == 0]["question_id"].tolist())
        low_conf = int(st.session_state["settings"].get("review_low_confidence_threshold", 60))
        if "confidence" in last_attempts.columns:
            confidence_series = last_attempts["confidence"].fillna(101)
            review_ids.update(
                last_attempts[confidence_series <= low_conf]["question_id"].tolist()
            )
        days_threshold = int(st.session_state["settings"].get("review_elapsed_days", 7))
        cutoff = dt.datetime.now() - dt.timedelta(days=days_threshold)
        review_ids.update(
            last_attempts[last_attempts["created_at"] <= cutoff]["question_id"].tolist()
        )
    srs_due = db.get_due_srs()
    if not srs_due.empty:
        review_ids.update(srs_due["question_id"].tolist())
    return {str(qid) for qid in review_ids if pd.notna(qid)}


def parse_explanation_sections(text: str) -> Tuple[str, List[Tuple[str, str]]]:
    if not text:
        return "", []
    lines = [line.strip() for line in str(text).splitlines() if line.strip()]
    sections: List[Tuple[str, str]] = []
    summary = ""
    for line in lines:
        match = re.match(r"^ã€([^ã€‘]+)ã€‘(.*)$", line)
        if match:
            label = match.group(1).strip()
            content = match.group(2).strip()
        else:
            label = "è£œè¶³"
            content = line.strip()
        sections.append((label, content))
        if not summary and label in ("è¦ç‚¹", "çµè«–") and content:
            summary = content
    if not summary and lines:
        summary = lines[0]
    summary = summary.strip()
    if len(summary) > 80:
        summary = summary[:77] + "â€¦"
    return summary, sections


def render_explanation_content(row: pd.Series) -> None:
    explanation = row.get("explanation", "")
    summary, sections = parse_explanation_sections(explanation)
    if not explanation:
        st.write("è§£èª¬ãŒæœªç™»éŒ²ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã‹ã‚‰è§£ç­”ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã¿ã¾ã—ã‚‡ã†ã€‚")
        return
    st.markdown(f"**è¦ç‚¹ç‰ˆ**ï¼š{summary}")
    with st.expander("è©³ç´°è§£èª¬ã‚’ã²ã‚‰ã", expanded=False):
        for label, content in sections:
            if not content:
                continue
            if label == "ãƒŸãƒ‹å›³":
                st.markdown(f"**{label}**")
                st.markdown(content, unsafe_allow_html=True)
            else:
                st.markdown(f"- **{label}**ï¼š{content}")
        similar = compute_similarity(row["id"])
        if not similar.empty:
            st.markdown("#### é¡ä¼¼å•é¡Œ")
            st.dataframe(similar, use_container_width=True)


def estimate_theta(attempts: pd.DataFrame, df: pd.DataFrame) -> Optional[float]:
    if attempts.empty:
        return None
    merged = attempts.merge(
        df[["id", "difficulty"]], left_on="question_id", right_on="id", how="left"
    )
    merged = merged.dropna(subset=["difficulty"])
    if merged.empty:
        return None
    difficulties = (merged["difficulty"].astype(float) - 3.0) * 0.7
    responses = merged["is_correct"].astype(float)
    theta = 0.0
    for _ in range(10):
        logits = theta - difficulties
        probs = 1.0 / (1.0 + np.exp(-logits))
        gradient = np.sum(responses - probs)
        hessian = -np.sum(probs * (1 - probs))
        if abs(hessian) < 1e-6:
            break
        theta -= gradient / hessian
        if abs(gradient) < 1e-4:
            break
    return float(theta)


def recommend_adaptive_questions(
    df: pd.DataFrame,
    attempts: pd.DataFrame,
    theta: float,
    limit: int = 10,
    low_conf_threshold: int = 70,
) -> pd.DataFrame:
    candidates = df.copy()
    candidates["difficulty"] = candidates["difficulty"].fillna(DIFFICULTY_DEFAULT)
    candidates["difficulty_scaled"] = (candidates["difficulty"].astype(float) - 3.0) * 0.7
    candidates["priority"] = np.where(
        candidates["difficulty_scaled"] >= theta,
        candidates["difficulty_scaled"] - theta,
        (theta - candidates["difficulty_scaled"]) * 1.5,
    )
    if not attempts.empty:
        attempts["created_at"] = pd.to_datetime(attempts["created_at"])
        last_attempts = attempts.sort_values("created_at").groupby("question_id").tail(1)
        if "confidence" in last_attempts:
            confidence_series = last_attempts["confidence"].fillna(0)
        else:
            confidence_series = pd.Series(0, index=last_attempts.index)
        mastered_ids = last_attempts[
            (last_attempts["is_correct"] == 1)
            & (confidence_series >= low_conf_threshold)
        ]["question_id"].tolist()
        if mastered_ids:
            candidates = candidates[~candidates["id"].isin(mastered_ids)]
    ranked = candidates.sort_values(["priority", "difficulty"], ascending=[True, False])
    return ranked.head(limit)


def compute_tricky_vocab_heatmap(
    attempts: pd.DataFrame, df: pd.DataFrame, top_n: int = 12
) -> pd.DataFrame:
    wrong = attempts[attempts["is_correct"] == 0]
    if wrong.empty:
        return pd.DataFrame()
    merged = wrong.merge(
        df[["id", "question", "category", "tags"]],
        left_on="question_id",
        right_on="id",
        how="left",
    )
    records: List[Dict[str, object]] = []
    pattern = re.compile(r"[ä¸€-é¾ ã-ã‚“ã‚¡-ãƒ³A-Za-z0-9]{2,}")
    for _, row in merged.iterrows():
        text = f"{row.get('question', '')} {row.get('tags', '')}"
        words = {w for w in pattern.findall(str(text)) if len(w) >= 2}
        for word in list(words)[:20]:
            records.append({"word": word, "category": row.get("category", "æœªåˆ†é¡")})
    if not records:
        return pd.DataFrame()
    freq = pd.DataFrame(records)
    counts = freq.groupby(["word", "category"]).size().reset_index(name="count")
    totals = counts.groupby("word")["count"].sum().reset_index(name="total")
    top_words = totals.nlargest(top_n, "total")["word"]
    heatmap_df = counts[counts["word"].isin(top_words)]
    return heatmap_df


def compute_most_improved_topic(attempts: pd.DataFrame, df: pd.DataFrame) -> Optional[Dict[str, object]]:
    merged = attempts.merge(df[["id", "topic"]], left_on="question_id", right_on="id", how="left")
    merged = merged.dropna(subset=["topic"])
    if merged.empty:
        return None
    improvements: List[Dict[str, object]] = []
    for topic, group in merged.groupby("topic"):
        if len(group) < 4:
            continue
        group = group.sort_values("created_at")
        window = max(1, len(group) // 3)
        early = group.head(window)["is_correct"].mean()
        late = group.tail(window)["is_correct"].mean()
        improvements.append(
            {
                "topic": topic,
                "delta": late - early,
                "early": early,
                "late": late,
                "attempts": len(group),
            }
        )
    if not improvements:
        return None
    best = max(improvements, key=lambda x: x["delta"])
    if best["delta"] <= 0:
        return None
    return best


def register_keyboard_shortcuts(mapping: Dict[str, str]) -> None:
    if not mapping:
        return
    html(
        """
        <script>
        (function() {
            const mapping = %s;
            document.addEventListener('keydown', function(event) {
                const active = document.activeElement;
                if (active && ['input', 'textarea', 'select'].includes(active.tagName.toLowerCase())) {
                    return;
                }
                const key = event.key ? event.key.toLowerCase() : '';
                const label = mapping[key];
                if (!label) {
                    return;
                }
                const doc = window.parent ? window.parent.document : document;
                const buttons = doc.querySelectorAll('button');
                for (const btn of buttons) {
                    if (!btn.innerText) {
                        continue;
                    }
                    if (btn.innerText.trim().startsWith(label.trim())) {
                        event.preventDefault();
                        btn.click();
                        break;
                    }
                }
            }, true);
        })();
        </script>
        """ % json.dumps({k.lower(): v for k, v in mapping.items()}, ensure_ascii=False),
        height=0,
    )
def decode_uploaded_file(file: "UploadedFile") -> List[Tuple[str, pd.DataFrame]]:
    filename = file.name
    suffix = Path(filename).suffix.lower()
    dataframes = []
    bytes_data = file.getvalue()
    if suffix == ".zip":
        with zipfile.ZipFile(io.BytesIO(bytes_data)) as z:
            for inner in z.infolist():
                if inner.is_dir():
                    continue
                inner_suffix = Path(inner.filename).suffix.lower()
                with z.open(inner) as f:
                    df = read_tabular(f.read(), inner_suffix)
                    dataframes.append((inner.filename, df))
    else:
        df = read_tabular(bytes_data, suffix)
        dataframes.append((filename, df))
    return dataframes


def read_tabular(data: bytes, suffix: str) -> pd.DataFrame:
    encoding_options = ["utf-8", "cp932"]
    if suffix in [".csv", ".txt", ".tsv", ""]:
        for enc in encoding_options:
            try:
                return pd.read_csv(io.BytesIO(data), encoding=enc)
            except Exception:
                continue
        return pd.read_csv(io.BytesIO(data))
    elif suffix in [".xlsx", ".xlsm", ".xls"]:
        return pd.read_excel(io.BytesIO(data))
    else:
        raise ValueError("ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™")


def guess_dataset_kind(df: pd.DataFrame) -> str:
    cols = set(df.columns.str.lower())
    if {"choice1", "choice2", "choice3", "choice4"}.issubset(cols):
        return MAPPING_KIND_QUESTIONS
    if "correct_number" in cols or "correct_label" in cols or "correct_text" in cols:
        return MAPPING_KIND_ANSWERS
    return MAPPING_KIND_QUESTIONS


def store_uploaded_file(file: "UploadedFile", timestamp: str) -> Path:
    target_dir = UPLOAD_DIR / timestamp
    target_dir.mkdir(parents=True, exist_ok=True)
    path = target_dir / file.name
    with open(path, "wb") as f:
        f.write(file.getbuffer())
    return path


def init_session_state() -> None:
    defaults = {
        "nav": "ãƒ›ãƒ¼ãƒ ",
        "current_question": None,
        "attempt_start": None,
        "exam_session": None,
        "import_state": {},
        "global_search_input": "",
        "global_search_query": "",
        "global_search_submitted": False,
        "global_search_should_clear": False,
        "global_search_pending": None,
        "settings": {
            "shuffle_choices": True,
            "theme": "ãƒ©ã‚¤ãƒˆ",
            "font_size": "æ¨™æº–",
            "timer": True,
            "sm2_initial_ease": 2.5,
            "auto_advance": False,
            "review_low_confidence_threshold": 60,
            "review_elapsed_days": 7,
        },
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def main() -> None:
    st.set_page_config(page_title="å®…å»º10å¹´ãƒ‰ãƒªãƒ«", layout="wide")
    init_session_state()
    if st.session_state.get("global_search_should_clear"):
        clear_global_search()
        st.session_state["global_search_should_clear"] = False
    pending_search = st.session_state.pop("global_search_pending", None)
    if pending_search:
        query = str(pending_search.get("query", "") or "").strip()
        submitted = bool(pending_search.get("submitted"))
        st.session_state["global_search_input"] = query
        st.session_state["global_search_query"] = query
        st.session_state["global_search_submitted"] = submitted
    apply_user_preferences()
    engine = get_engine()
    db = DBManager(engine)
    db.initialize_from_csv()
    df = load_questions_df()
    search_dictionary = build_search_dictionary(df)

    sidebar = st.sidebar
    sidebar.title("å®…å»º10å¹´ãƒ‰ãƒªãƒ«")
    sidebar.text_input(
        "ğŸ” æ¨ªæ–­æ¤œç´¢",
        key="global_search_input",
        placeholder="æŠµå½“æ¨© ä»£ä¾¡å¼æ¸ˆ / å†å»ºç¯‰ä¸å¯ ãªã©",
        help="Enterã‚­ãƒ¼ã¾ãŸã¯ã€æ¤œç´¢ã€ãƒœã‚¿ãƒ³ã§å®Ÿè¡Œã—ã¾ã™ã€‚",
        on_change=trigger_global_search,
    )
    suggestion_container = sidebar.container()
    current_input = st.session_state.get("global_search_input", "")
    suggestions = match_search_suggestions(search_dictionary, current_input)
    if suggestions:
        with suggestion_container:
            st.caption("å€™è£œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (ã‚¯ãƒªãƒƒã‚¯ã§æ¤œç´¢æ¬„ã«åæ˜ ã•ã‚Œã¾ã™)")
            suggestion_cols = st.columns(2)
            for idx, keyword in enumerate(suggestions):
                col = suggestion_cols[idx % 2]
                if col.button(keyword, key=f"global_suggest_{idx}", type="secondary"):
                    set_global_search_query(keyword)
                    safe_rerun()
    search_action_cols = sidebar.columns(2)
    if search_action_cols[0].button("æ¤œç´¢", key="global_search_button"):
        trigger_global_search()
    if search_action_cols[1].button(
        "æ¡ä»¶ã‚¯ãƒªã‚¢",
        key="global_search_clear",
        type="secondary",
    ):
        request_clear_global_search()
        safe_rerun()
    search_query = st.session_state.get("global_search_query", "")
    with sidebar.expander("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ’ãƒ³ãƒˆ", expanded=False):
        st.caption("ã‚ˆãä½¿ã†èªå¥ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨æ¤œç´¢æ¬„ã«è‡ªå‹•å…¥åŠ›ã•ã‚Œã¾ã™ã€‚")
        hint_cols = st.columns(2)
        for idx, keyword in enumerate(GLOBAL_SEARCH_SUGGESTIONS):
            if hint_cols[idx % 2].button(keyword, key=f"global_search_hint_{idx}"):
                set_global_search_query(keyword)
                search_query = keyword
                safe_rerun()
    sidebar.divider()
    nav = sidebar.radio(
        "ãƒ¡ãƒ‹ãƒ¥ãƒ¼",
        ["ãƒ›ãƒ¼ãƒ ", "å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰", "æ¨¡è©¦", "å¼±ç‚¹å¾©ç¿’", "çµ±è¨ˆ", "ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›", "è¨­å®š"],
        index=["ãƒ›ãƒ¼ãƒ ", "å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰", "æ¨¡è©¦", "å¼±ç‚¹å¾©ç¿’", "çµ±è¨ˆ", "ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›", "è¨­å®š"].index(st.session_state.get("nav", "ãƒ›ãƒ¼ãƒ ")),
    )
    st.session_state["nav"] = nav
    with sidebar.expander("ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰", expanded=False):
        st.markdown(
            "\n".join(
                [
                    "- **ãƒ›ãƒ¼ãƒ **ï¼šé€²æ—ã‚µãƒãƒªãƒ¼ã¨æœ€è¿‘ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ã‚’ç¢ºèªã§ãã¾ã™ã€‚",
                    "- **å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰**ï¼šç›®çš„åˆ¥ã‚¿ãƒ–ã‹ã‚‰æœ¬è©¦é¨“æ¼”ç¿’ã‚„ãƒ‰ãƒªãƒ«ã€é©å¿œå­¦ç¿’ã‚’é¸æŠã—ã¾ã™ã€‚",
                    "- **æ¨¡è©¦**ï¼šå¹´åº¦ã‚„å‡ºé¡Œæ–¹å¼ã‚’æŒ‡å®šã—ã¦æœ¬ç•ªåŒæ§˜ã®æ¨¡è©¦ã‚’é–‹å§‹ã—ã¾ã™ã€‚",
                    "- **å¼±ç‚¹å¾©ç¿’**ï¼šSRSã®æœŸé™ãŒæ¥ãŸå•é¡Œã‚’ã¾ã¨ã‚ã¦å¾©ç¿’ã—ã¾ã™ã€‚",
                    "- **çµ±è¨ˆ**ï¼šåˆ†é‡åˆ¥ã®æˆç¸¾ã‚„æ™‚é–“åˆ†æã‚’æŠŠæ¡ã§ãã¾ã™ã€‚",
                    "- **ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›**ï¼šCSV/ZIPã®å–ã‚Šè¾¼ã¿ã‚„å±¥æ­´ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’è¡Œã„ã¾ã™ã€‚",
                    "- **è¨­å®š**ï¼šã‚¿ã‚¤ãƒãƒ¼ã‚„ã‚·ãƒ£ãƒƒãƒ•ãƒ«ãªã©å­¦ç¿’ä½“é¨“ã®å¥½ã¿ã‚’èª¿æ•´ã—ã¾ã™ã€‚",
                ]
            )
        )

    if search_query and st.session_state.get("global_search_submitted"):
        render_global_search_panel(db, df, search_query)
        st.divider()

    if nav == "ãƒ›ãƒ¼ãƒ ":
        render_home(db, df)
    elif nav == "å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰":
        render_learning(db, df)
    elif nav == "æ¨¡è©¦":
        render_mock_exam(db, df)
    elif nav == "å¼±ç‚¹å¾©ç¿’":
        render_srs(db)
    elif nav == "çµ±è¨ˆ":
        render_stats(db, df)
    elif nav == "ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›":
        render_data_io(db)
    elif nav == "è¨­å®š":
        render_settings()


def render_home(db: DBManager, df: pd.DataFrame) -> None:
    st.title("ãƒ›ãƒ¼ãƒ ")
    attempts = db.get_attempt_stats()
    st.markdown("### ã‚µãƒãƒªãƒ¼")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("è¨­å•æ•°", len(df))
    with col2:
        st.metric("å­¦ç¿’å±¥æ­´", len(attempts))
    with col3:
        coverage = attempts["year"].nunique() / max(df["year"].nunique(), 1) * 100 if not attempts.empty else 0
        st.metric("å¹´åº¦ã‚«ãƒãƒ¬ãƒƒã‚¸", f"{coverage:.0f}%")
    st.info("éå»å•ãƒ‡ãƒ¼ã‚¿ã¨è§£ç­”ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã—ã‚‡ã†ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã‹ã‚‰å–ã‚Šè¾¼ã‚ã¾ã™ã€‚")
    st.markdown("### æœ€è¿‘ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    with db.engine.connect() as conn:
        logs = pd.read_sql(select(import_logs_table).order_by(import_logs_table.c.id.desc()).limit(5), conn)
    if logs.empty:
        st.write("ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.dataframe(logs)


def render_learning(db: DBManager, df: pd.DataFrame) -> None:
    st.title("å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰")
    if df.empty:
        st.warning("è¨­å•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return
    tabs = st.tabs(["æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰", "é©å¿œå­¦ç¿’", "åˆ†é‡åˆ¥ãƒ‰ãƒªãƒ«", "å¹´åº¦åˆ¥æ¼”ç¿’", "å¼±ç‚¹å…‹æœãƒ¢ãƒ¼ãƒ‰"])
    with tabs[0]:
        render_full_exam_lane(db, df)
    with tabs[1]:
        render_adaptive_lane(db, df)
    with tabs[2]:
        render_subject_drill_lane(db, df)
    with tabs[3]:
        render_year_drill_lane(db, df)
    with tabs[4]:
        render_weakness_lane(db, df)


def render_full_exam_lane(db: DBManager, df: pd.DataFrame) -> None:
    st.subheader("æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰")
    st.caption("50å•ãƒ»120åˆ†ã®æœ¬è©¦é¨“åŒç­‰ç’°å¢ƒã§å¾—ç‚¹åŠ›ã¨æ™‚é–“é…åˆ†ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚")
    if len(df) < 50:
        st.info("50å•ã®å‡ºé¡Œã«ã¯æœ€ä½50å•ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        return
    session: Optional[ExamSession] = st.session_state.get("exam_session")
    if session is None or session.mode != "æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰":
        if st.button(
            "50å•æ¨¡è©¦ã‚’é–‹å§‹",
            key="start_full_exam",
            help="æœ¬è©¦é¨“ã¨åŒã˜50å•ãƒ»120åˆ†æ§‹æˆã§ä¸€æ°—ã«æ¼”ç¿’ã—ã¾ã™ã€‚çµæœã¯çµ±è¨ˆã«åæ˜ ã•ã‚Œã¾ã™ã€‚",
        ):
            questions = stratified_exam(df)
            if not questions:
                st.warning("å‡ºé¡Œå¯èƒ½ãªå•é¡ŒãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
                return
            st.session_state.pop("exam_result_æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰", None)
            st.session_state["exam_session"] = ExamSession(
                id=None,
                name=f"æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰ {dt.datetime.now():%Y%m%d-%H%M}",
                questions=questions,
                started_at=dt.datetime.now(),
                year_mode="å±¤åŒ–ãƒ©ãƒ³ãƒ€ãƒ 50",
                mode="æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰",
            )
            session = st.session_state.get("exam_session")
    session = st.session_state.get("exam_session")
    if session and session.mode == "æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰":
        render_exam_session_body(db, df, session, key_prefix="main_exam")
    result = st.session_state.get("exam_result_æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰")
    if result:
        display_exam_result(result)


def render_adaptive_lane(db: DBManager, df: pd.DataFrame) -> None:
    st.subheader("é©å¿œå­¦ç¿’")
    st.caption("å›ç­”å±¥æ­´ã‹ã‚‰èƒ½åŠ›Î¸ã‚’æ¨å®šã—ã€ä¼¸ã³ã—ã‚ã®å¤§ãã„é›£åº¦ã‚’å„ªå…ˆå‡ºé¡Œã—ã¾ã™ã€‚")
    attempts = db.get_attempt_stats()
    if attempts.empty:
        st.info("å­¦ç¿’å±¥æ­´ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰ã‚„ãƒ‰ãƒªãƒ«ã§å–ã‚Šçµ„ã‚“ã§ã¿ã¾ã—ã‚‡ã†ã€‚")
        return
    theta = estimate_theta(attempts, df)
    if theta is None:
        st.info("æ¨å®šã«å¿…è¦ãªé›£æ˜“åº¦ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚å•é¡Œã«é›£æ˜“åº¦ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    st.metric("æ¨å®šèƒ½åŠ›Î¸", f"{theta:.2f}")
    low_conf = int(st.session_state["settings"].get("review_low_confidence_threshold", 60))
    recommended = recommend_adaptive_questions(df, attempts, theta, low_conf_threshold=low_conf)
    if recommended.empty:
        st.info("ãŠã™ã™ã‚ã§ãã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ¡ä»¶ã‚’è¦‹ç›´ã™ã‹ã€æ–°ã—ã„å•é¡Œã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        return
    st.markdown("#### æ¨å¥¨å•é¡Œãƒªã‚¹ãƒˆ (ä¸Šä½10ä»¶)")
    display = recommended[["id", "year", "q_no", "category", "difficulty", "priority"]].rename(
        columns={
            "id": "å•é¡ŒID",
            "year": "å¹´åº¦",
            "q_no": "å•ç•ª",
            "category": "åˆ†é‡",
            "difficulty": "é›£æ˜“åº¦",
            "priority": "æ¨å¥¨åº¦",
        }
    )
    st.dataframe(display.set_index("å•é¡ŒID"), use_container_width=True)
    selected_id = st.selectbox(
        "å–ã‚Šçµ„ã‚€å•é¡Œ",
        recommended["id"],
        format_func=lambda x: format_question_label(df, x),
        key="adaptive_question_select",
    )
    row = df[df["id"] == selected_id].iloc[0]
    render_question_interaction(db, row, attempt_mode="adaptive", key_prefix="adaptive")


def render_subject_drill_lane(db: DBManager, df: pd.DataFrame) -> None:
    st.subheader("åˆ†é‡åˆ¥ãƒ‰ãƒªãƒ«")
    st.caption("æ°‘æ³•ãƒ»å€Ÿåœ°å€Ÿå®¶æ³•ãƒ»éƒ½å¸‚è¨ˆç”»æ³•ãƒ»å»ºç¯‰åŸºæº–æ³•ãƒ»ç¨ãƒ»é‘‘å®šè©•ä¾¡ãƒ»å®…å»ºæ¥­æ³•ã¨ã„ã£ãŸãƒ†ãƒ¼ãƒã‚’ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆã§é›ãˆã¾ã™ã€‚")
    with st.expander("å‡ºé¡Œæ¡ä»¶", expanded=True):
        preset = st.selectbox(
            "ã‚¯ã‚¤ãƒƒã‚¯ãƒ—ãƒªã‚»ãƒƒãƒˆ",
            list(SUBJECT_PRESETS.keys()),
            help="ä»£è¡¨çš„ãªçµã‚Šè¾¼ã¿æ¡ä»¶ã‚’ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§é©ç”¨ã§ãã¾ã™ã€‚",
            key="subject_preset",
        )
        if st.button("ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’é©ç”¨", key="subject_apply_preset"):
            config = SUBJECT_PRESETS[preset]
            st.session_state["subject_categories"] = config["categories"]
            st.session_state["subject_difficulty"] = config["difficulty"]
            st.session_state["subject_review_only"] = config["review_only"]
            st.session_state["subject_topics"] = config.get("topics", [])
            st.session_state["subject_keyword"] = ""
            safe_rerun()
        categories = st.multiselect(
            "åˆ†é‡",
            CATEGORY_CHOICES,
            default=CATEGORY_CHOICES,
            key="subject_categories",
        )
        topic_options = sorted({t for t in df["topic"].dropna().unique() if str(t).strip()})
        selected_topics = st.multiselect(
            "ãƒ†ãƒ¼ãƒ",
            topic_options,
            default=[],
            key="subject_topics",
        )
        difficulties = st.slider(
            "é›£æ˜“åº¦",
            1,
            5,
            (1, 5),
            key="subject_difficulty",
            help="1ã¯æ˜“ã—ã„ã€œ5ã¯é›£ã—ã„å•é¡Œã§ã™ã€‚",
        )
        keyword = st.text_input(
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§çµã‚Šè¾¼ã¿ (å•é¡Œæ–‡/ã‚¿ã‚°)",
            key="subject_keyword",
            help="èªå¥ã‚’å…¥åŠ›ã™ã‚‹ã¨å•é¡Œæ–‡ã¨ã‚¿ã‚°ã‹ã‚‰éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢ã—ã¾ã™ã€‚",
        )
        review_only = st.checkbox(
            "å¾©ç¿’ã ã‘è¡¨ç¤º (èª¤ç­”ãƒ»ä½ç¢ºä¿¡ãƒ»çµŒéæ—¥æ•°)",
            value=st.session_state.get("subject_review_only", False),
            key="subject_review_only",
        )
    filtered = df[
        df["category"].isin(categories)
        & df["difficulty"].between(difficulties[0], difficulties[1])
    ]
    if selected_topics:
        filtered = filtered[filtered["topic"].isin(selected_topics)]
    if keyword:
        keyword_lower = keyword.lower()
        filtered = filtered[
            filtered["question"].str.lower().str.contains(keyword_lower)
            | filtered["tags"].fillna("").str.lower().str.contains(keyword_lower)
        ]
    if review_only:
        review_ids = get_review_candidate_ids(db)
        if not review_ids:
            st.info("å¾©ç¿’å¯¾è±¡ã®å•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’å±¥æ­´ã‚’å¢—ã‚„ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
            return
        filtered = filtered[filtered["id"].isin(review_ids)]
    if filtered.empty:
        st.warning("æ¡ä»¶ã«åˆè‡´ã™ã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
        return
    st.caption(f"ç¾åœ¨ã®æ¡ä»¶ã«åˆè‡´ã™ã‚‹å•é¡Œã¯ {len(filtered)} ä»¶ã§ã™ã€‚")
    question_id = st.selectbox(
        "å‡ºé¡Œå•é¡Œ",
        filtered["id"],
        format_func=lambda x: format_question_label(filtered, x),
        key="subject_question_select",
    )
    row = filtered[filtered["id"] == question_id].iloc[0]
    render_question_interaction(db, row, attempt_mode="subject_drill", key_prefix="subject")


def render_year_drill_lane(db: DBManager, df: pd.DataFrame) -> None:
    st.subheader("å¹´åº¦åˆ¥æ¼”ç¿’")
    st.caption("å¹´åº¦ã”ã¨ã®å‡ºé¡Œã‚’é€šã—æ¼”ç¿’ã—ã€æœ¬è©¦é¨“æœ¬ç•ªã¨åŒã˜æµã‚Œã§çŸ¥è­˜ã‚’å®šç€ã•ã›ã¾ã™ã€‚")
    years = sorted(df["year"].unique(), reverse=True)
    if not years:
        st.info("å¹´åº¦æƒ…å ±ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    selected_year = st.selectbox("å¹´åº¦", years, key="year_drill_year")
    subset = df[df["year"] == selected_year].sort_values("q_no")
    if subset.empty:
        st.warning("é¸æŠã—ãŸå¹´åº¦ã®å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    total = len(subset)
    progress_key = "year_drill_index"
    stored_year_key = "year_drill_current_year"
    if st.session_state.get(stored_year_key) != selected_year:
        st.session_state[stored_year_key] = selected_year
        st.session_state[progress_key] = 0
    index = st.session_state.get(progress_key, 0)
    index = max(0, min(index, total - 1))
    current_row = subset.iloc[index]
    st.progress((index + 1) / total)

    def go_prev() -> None:
        st.session_state[progress_key] = max(0, index - 1)

    def go_next() -> None:
        st.session_state[progress_key] = min(total - 1, index + 1)

    navigation = QuestionNavigation(
        has_prev=index > 0,
        has_next=index < total - 1,
        on_prev=go_prev,
        on_next=go_next,
        label=f"{index + 1}/{total} å•ã‚’å­¦ç¿’ä¸­",
    )
    render_question_interaction(
        db,
        current_row,
        attempt_mode="year_drill",
        key_prefix="year",
        navigation=navigation,
    )


def render_weakness_lane(db: DBManager, df: pd.DataFrame) -> None:
    st.subheader("å¼±ç‚¹å…‹æœãƒ¢ãƒ¼ãƒ‰")
    st.caption("èª¤ç­”ãƒ»ä½æ­£ç­”ç‡ãƒ»æ™‚é–“è¶…éãŒç›®ç«‹ã¤å•é¡Œã‚’å„ªå…ˆçš„ã«å‡ºé¡Œã—ã€å¾—ç‚¹ã®åº•ä¸Šã’ã‚’å›³ã‚Šã¾ã™ã€‚")
    attempts = db.get_attempt_stats()
    if attempts.empty:
        st.info("å­¦ç¿’å±¥æ­´ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰ã‚„ãƒ‰ãƒªãƒ«ã§å–ã‚Šçµ„ã‚“ã§ã¿ã¾ã—ã‚‡ã†ã€‚")
        return
    summary = (
        attempts.groupby(["question_id", "category"])
        .agg(
            attempts_count=("is_correct", "count"),
            correct_count=("is_correct", "sum"),
            avg_seconds=("seconds", "mean"),
        )
        .reset_index()
    )
    summary["accuracy"] = summary["correct_count"] / summary["attempts_count"].replace(0, np.nan)
    summary["accuracy"] = summary["accuracy"].fillna(0)
    summary["avg_seconds"] = summary["avg_seconds"].fillna(0)
    summary["priority"] = (1 - summary["accuracy"]) * summary["attempts_count"] + np.where(
        summary["avg_seconds"] > 90,
        1,
        0,
    )
    merged = summary.merge(df[["id", "year", "q_no", "question"]], left_on="question_id", right_on="id", how="left")
    merged = merged.sort_values(["priority", "accuracy"], ascending=[False, True])
    st.markdown("#### å„ªå…ˆå‡ºé¡Œãƒªã‚¹ãƒˆ")
    with st.expander("ä¸¦ã³æ›¿ãˆãƒ»ãƒ•ã‚£ãƒ«ã‚¿", expanded=False):
        category_options = sorted({str(cat) for cat in merged["category"].dropna()})
        selected_categories = st.multiselect(
            "åˆ†é‡",
            category_options,
            default=category_options,
            help="é‡ç‚¹çš„ã«å¾©ç¿’ã—ãŸã„åˆ†é‡ã‚’é¸ã³ã¾ã™ã€‚",
            key="weakness_categories",
        )
        max_attempts = int(merged["attempts_count"].max()) if not merged.empty else 1
        min_attempts = int(merged["attempts_count"].min()) if not merged.empty else 0
        if min_attempts == max_attempts:
            attempts_threshold = max_attempts
            st.caption(f"æŒ‘æˆ¦å›æ•°ãƒ•ã‚£ãƒ«ã‚¿: {max_attempts} å›ã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚")
        else:
            attempts_threshold = st.slider(
                "æœ€ä½æŒ‘æˆ¦å›æ•°",
                min_attempts,
                max_attempts,
                min(min_attempts + 1, max_attempts),
                help="æŒ‡å®šå›æ•°ä»¥ä¸Šå–ã‚Šçµ„ã‚“ã å•é¡Œã‚’å¯¾è±¡ã«ã—ã¾ã™ã€‚",
                key="weakness_attempts_threshold",
            )
        accuracy_ceiling = st.slider(
            "æ­£ç­”ç‡ã®ä¸Šé™ (%)",
            0,
            100,
            70,
            step=5,
            help="ã“ã®å€¤ã‚ˆã‚Šæ­£ç­”ç‡ãŒé«˜ã„å•é¡Œã¯ãƒªã‚¹ãƒˆã‹ã‚‰é™¤å¤–ã—ã¾ã™ã€‚",
            key="weakness_accuracy_ceiling",
        )
        sort_option = st.selectbox(
            "ä¸¦ã³é †",
            ["å„ªå…ˆåº¦ãŒé«˜ã„é †", "æ­£ç­”ç‡ãŒä½ã„é †", "æŒ‘æˆ¦å›æ•°ãŒå¤šã„é †", "å¹´åº¦ãŒæ–°ã—ã„é †"],
            help="å¾©ç¿’ãƒªã‚¹ãƒˆã®ä¸¦ã³æ›¿ãˆåŸºæº–ã‚’å¤‰æ›´ã—ã¾ã™ã€‚",
            key="weakness_sort",
        )
    filtered = merged.copy()
    if selected_categories:
        filtered = filtered[filtered["category"].isin(selected_categories)]
    if attempts_threshold:
        filtered = filtered[filtered["attempts_count"] >= attempts_threshold]
    filtered = filtered[filtered["accuracy"] * 100 <= accuracy_ceiling]
    if sort_option == "æ­£ç­”ç‡ãŒä½ã„é †":
        filtered = filtered.sort_values(["accuracy", "attempts_count"], ascending=[True, False])
    elif sort_option == "æŒ‘æˆ¦å›æ•°ãŒå¤šã„é †":
        filtered = filtered.sort_values(["attempts_count", "accuracy"], ascending=[False, True])
    elif sort_option == "å¹´åº¦ãŒæ–°ã—ã„é †":
        filtered = filtered.sort_values(["year", "priority"], ascending=[False, False])
    else:
        filtered = filtered.sort_values(["priority", "accuracy"], ascending=[False, True])
    if filtered.empty:
        st.info("æ¡ä»¶ã«åˆè‡´ã™ã‚‹å¼±ç‚¹å€™è£œãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿è¨­å®šã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
        return
    display_df = filtered.head(15)[
        [
            "question_id",
            "category",
            "year",
            "q_no",
            "accuracy",
            "attempts_count",
            "avg_seconds",
        ]
    ].rename(
        columns={
            "question_id": "å•é¡ŒID",
            "category": "åˆ†é‡",
            "year": "å¹´åº¦",
            "q_no": "å•",
            "accuracy": "æ­£ç­”ç‡",
            "attempts_count": "æŒ‘æˆ¦å›æ•°",
            "avg_seconds": "å¹³å‡è§£ç­”æ™‚é–“(ç§’)",
        }
    )
    display_df["æ­£ç­”ç‡"] = display_df["æ­£ç­”ç‡"].astype(float) * 100
    st.dataframe(
        display_df.set_index("å•é¡ŒID"),
        use_container_width=True,
        column_config={
            "åˆ†é‡": st.column_config.TextColumn("åˆ†é‡", help="å¾©ç¿’å¯¾è±¡ã®ã‚«ãƒ†ã‚´ãƒªã§ã™ã€‚"),
            "å¹´åº¦": st.column_config.NumberColumn("å¹´åº¦", format="%d", help="æœ€æ–°å¹´åº¦ã‚’ã‚¯ãƒªãƒƒã‚¯ã§ã‚½ãƒ¼ãƒˆã§ãã¾ã™ã€‚"),
            "å•": st.column_config.NumberColumn("å•", format="%d", help="å¹´åº¦å†…ã§ã®å•é¡Œç•ªå·ã§ã™ã€‚"),
            "æ­£ç­”ç‡": st.column_config.NumberColumn("æ­£ç­”ç‡", format="%.0f%%", help="ä½ã„ã»ã©å„ªå…ˆçš„ã«å¾©ç¿’ã—ãŸã„å•é¡Œã§ã™ã€‚"),
            "æŒ‘æˆ¦å›æ•°": st.column_config.NumberColumn("æŒ‘æˆ¦å›æ•°", format="%d", help="å–ã‚Šçµ„ã‚“ã å›æ•°ã§ã™ã€‚"),
            "å¹³å‡è§£ç­”æ™‚é–“(ç§’)": st.column_config.NumberColumn(
                "å¹³å‡è§£ç­”æ™‚é–“(ç§’)",
                format="%.1f",
                help="é•·è€ƒã—ãŸå•é¡Œã¯ãƒŸã‚¹ã®æ¸©åºŠã«ãªã‚ŠãŒã¡ã§ã™ã€‚",
            ),
        },
    )
    candidates = filtered[~filtered["id"].isna()]
    if candidates.empty:
        st.info("å¼±ç‚¹å€™è£œã®å•é¡Œã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å±¥æ­´ã‚’å¢—ã‚„ã—ã¾ã—ã‚‡ã†ã€‚")
        return
    selected_qid = st.selectbox(
        "å¾©ç¿’ã™ã‚‹å•é¡Œ",
        candidates["id"],
        format_func=lambda x: format_question_label(df, x),
        key="weakness_question",
    )
    row = df[df["id"] == selected_qid].iloc[0]
    render_question_interaction(db, row, attempt_mode="weakness", key_prefix="weakness")


def render_exam_session_body(
    db: DBManager,
    df: pd.DataFrame,
    session: ExamSession,
    key_prefix: str,
    pass_line: float = 0.7,
) -> None:
    st.subheader(session.name)
    if st.session_state["settings"].get("timer", True):
        elapsed = dt.datetime.now() - session.started_at
        remaining = max(0, 120 * 60 - int(elapsed.total_seconds()))
        minutes, seconds = divmod(remaining, 60)
        st.info(f"æ®‹ã‚Šæ™‚é–“: {minutes:02d}:{seconds:02d}")
    responses: Dict[str, int] = {}
    choice_labels = ["â‘ ", "â‘¡", "â‘¢", "â‘£"]
    for qid in session.questions:
        row_df = df[df["id"] == qid]
        if row_df.empty:
            continue
        row = row_df.iloc[0]
        st.markdown(f"### {row['year']}å¹´ å•{row['q_no']}")
        st.markdown(f"**{row['category']} / {row['topic']}**")
        render_law_reference(row)
        st.markdown(row["question"], unsafe_allow_html=True)
        options = [row.get(f"choice{i}", "") for i in range(1, 5)]
        option_map = {
            idx + 1: f"{choice_labels[idx]} {options[idx]}" if options[idx] else choice_labels[idx]
            for idx in range(4)
        }
        choice = st.radio(
            f"å›ç­” ({qid})",
            list(option_map.keys()),
            format_func=lambda opt: option_map.get(opt, str(opt)),
            key=f"{key_prefix}_exam_{qid}",
            horizontal=True,
            index=None,
        )
        if choice is not None:
            responses[qid] = choice
    if st.button(
        "æ¡ç‚¹ã™ã‚‹",
        key=f"{key_prefix}_grade",
        help="ç¾åœ¨ã®å›ç­”ã‚’ä¿å­˜ã—ã€æ­£ç­”ç‡ã‚„åˆ†é‡åˆ¥çµ±è¨ˆã‚’è¡¨ç¤ºã—ã¾ã™ã€‚",
    ):
        evaluate_exam_attempt(db, df, session, responses, pass_line)


def evaluate_exam_attempt(
    db: DBManager,
    df: pd.DataFrame,
    session: ExamSession,
    responses: Dict[str, int],
    pass_line: float,
) -> None:
    total_questions = len(session.questions)
    correct = 0
    per_category: Dict[str, Dict[str, int]] = {}
    wrong_choices: List[Dict[str, object]] = []
    attempt_records: List[Tuple[str, int, bool]] = []
    duration = max((dt.datetime.now() - session.started_at).total_seconds(), 1)
    avg_seconds = duration / max(len(responses), 1)
    for qid in session.questions:
        row_df = df[df["id"] == qid]
        if row_df.empty:
            continue
        row = row_df.iloc[0]
        correct_choice = int(row.get("correct") or 0)
        choice = responses.get(qid)
        is_correct = choice is not None and correct_choice == choice
        if is_correct:
            correct += 1
        category = row.get("category", "ãã®ä»–")
        stats = per_category.setdefault(category, {"total": 0, "correct": 0})
        stats["total"] += 1
        if is_correct:
            stats["correct"] += 1
        attempt_records.append((qid, choice, is_correct))
        if not is_correct and correct_choice in range(1, 5):
            wrong_choices.append(
                {
                    "question": f"{row['year']}å¹´ å•{row['q_no']}",
                    "selected": choice,
                    "correct": correct_choice,
                    "category": category,
                }
            )
    finished_at = dt.datetime.now()
    exam_id = db.log_exam_result(
        {
            "name": session.name,
            "started_at": session.started_at,
            "finished_at": finished_at,
            "year_mode": session.year_mode,
            "score": correct,
        }
    )
    for qid, choice, is_correct in attempt_records:
        db.record_attempt(
            qid,
            choice,
            is_correct,
            seconds=int(avg_seconds),
            mode=session.mode,
            exam_id=exam_id,
            confidence=None,
            grade=None,
        )
    accuracy = correct / max(total_questions, 1)
    remaining_time = max(0, 120 * 60 - int(duration))
    answered = len(responses)
    unanswered = total_questions - answered
    expected_final = correct + unanswered * (correct / max(answered, 1)) if answered else 0
    result_payload = {
        "score": correct,
        "total": total_questions,
        "accuracy": accuracy,
        "pass_line": pass_line,
        "per_category": per_category,
        "wrong_choices": wrong_choices,
        "remaining_time": remaining_time,
        "expected_final": expected_final,
        "mode": session.mode,
        "exam_id": exam_id,
    }
    st.session_state[f"exam_result_{session.mode}"] = result_payload
    st.session_state["exam_session"] = None


def display_exam_result(result: Dict[str, object]) -> None:
    score = result["score"]
    total = result["total"]
    accuracy = result["accuracy"]
    pass_line = result["pass_line"]
    status = "âœ… åˆæ ¼ãƒ©ã‚¤ãƒ³åˆ°é”" if accuracy >= pass_line else "âš ï¸ åˆæ ¼ãƒ©ã‚¤ãƒ³æœªé”"
    st.markdown(f"### æ¡ç‚¹çµæœ â€” {status}")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å¾—ç‚¹", f"{score} / {total}")
    with col2:
        st.metric("æ­£ç­”ç‡", f"{accuracy * 100:.1f}%")
    with col3:
        threshold = int(total * pass_line)
        st.metric("åˆæ ¼ãƒ©ã‚¤ãƒ³", f"{threshold} ç‚¹")
    st.progress(min(accuracy / max(pass_line, 1e-6), 1.0))
    remaining_minutes, remaining_seconds = divmod(int(result["remaining_time"]), 60)
    st.metric(
        "æ®‹ã‚Šæ™‚é–“ Ã— æƒ³å®šåˆ°é”ç‚¹",
        f"{remaining_minutes:02d}:{remaining_seconds:02d} / {result['expected_final']:.1f} ç‚¹",
    )
    if result["per_category"]:
        radar_df = pd.DataFrame(
            [
                {
                    "category": category,
                    "accuracy": stats["correct"] / max(stats["total"], 1),
                }
                for category, stats in result["per_category"].items()
            ]
        )
        if not radar_df.empty:
            import altair as alt

            radar_df = pd.concat([radar_df, radar_df.iloc[[0]]], ignore_index=True)
            chart = (
                alt.Chart(radar_df)
                .mark_line(closed=True)
                .encode(
                    theta=alt.Theta("category", sort=None),
                    radius=alt.Radius("accuracy", scale=alt.Scale(domain=[0, 1])),
                )
                .properties(title="åˆ†é‡åˆ¥ã‚¹ã‚³ã‚¢ãƒ¬ãƒ¼ãƒ€ãƒ¼")
            )
            points = (
                alt.Chart(radar_df)
                .mark_point(size=80)
                .encode(
                    theta=alt.Theta("category", sort=None),
                    radius=alt.Radius("accuracy", scale=alt.Scale(domain=[0, 1])),
                )
            )
            st.altair_chart(chart + points, use_container_width=True)
    wrong_choices = result.get("wrong_choices", [])
    if wrong_choices:
        st.markdown("#### èª¤ç­”ã®ä»£æ›¿æ­£è§£è‚¢å‚¾å‘")
        wrong_df = pd.DataFrame(wrong_choices)
        option_map = {1: "â‘ ", 2: "â‘¡", 3: "â‘¢", 4: "â‘£"}
        wrong_df["é¸æŠè‚¢"] = wrong_df["selected"].map(option_map).fillna("æœªå›ç­”")
        wrong_df["æ­£è§£è‚¢"] = wrong_df["correct"].map({1: "â‘ ", 2: "â‘¡", 3: "â‘¢", 4: "â‘£"})
        st.dataframe(
            wrong_df[["question", "category", "é¸æŠè‚¢", "æ­£è§£è‚¢"]],
            use_container_width=True,
        )


def render_question_interaction(
    db: DBManager,
    row: pd.Series,
    attempt_mode: str,
    key_prefix: str,
    navigation: Optional[QuestionNavigation] = None,
) -> None:
    inject_ui_styles()
    last_question_key = f"{key_prefix}_last_question"
    feedback_key = f"{key_prefix}_feedback"
    selected_key = f"{key_prefix}_selected_{row['id']}"
    order_key = f"{key_prefix}_order_{row['id']}"
    explanation_key = f"{key_prefix}_explanation_{row['id']}"
    confidence_key = f"{key_prefix}_confidence_{row['id']}"
    help_state_key = f"{key_prefix}_help_visible"
    if st.session_state.get(last_question_key) != row["id"]:
        st.session_state[last_question_key] = row["id"]
        st.session_state.pop(feedback_key, None)
        st.session_state[selected_key] = None
        st.session_state[confidence_key] = 50
        st.session_state[order_key] = None
        st.session_state[explanation_key] = False
    choices = [row.get(f"choice{i}", "") for i in range(1, 5)]
    base_order = list(range(4))
    if st.session_state["settings"].get("shuffle_choices", True):
        random.seed(f"{row['id']}_{attempt_mode}")
        random.shuffle(base_order)
    if st.session_state.get(order_key) is None:
        st.session_state[order_key] = base_order.copy()
    order = st.session_state.get(order_key, base_order)
    choice_labels = ["â‘ ", "â‘¡", "â‘¢", "â‘£"]
    st.markdown(f"### {row['year']}å¹´ å•{row['q_no']}")
    st.markdown(f"**{row['category']} / {row['topic']}**")
    render_law_reference(row)
    st.markdown(row["question"], unsafe_allow_html=True)
    selected_choice = st.session_state.get(selected_key)
    button_labels: List[str] = []
    for idx in range(0, len(order), 2):
        cols = st.columns(2)
        for col_idx in range(2):
            pos = idx + col_idx
            if pos >= len(order):
                continue
            actual_idx = order[pos]
            label_text = choices[actual_idx]
            display_label = f"{choice_labels[actual_idx]} {label_text}".strip()
            button_labels.append(display_label or choice_labels[actual_idx])
            button_key = f"{key_prefix}_choice_{row['id']}_{actual_idx}"
            button_type = "primary" if selected_choice == actual_idx else "secondary"
            with cols[col_idx]:
                st.markdown('<div class="takken-choice-button">', unsafe_allow_html=True)
                if st.button(
                    display_label or choice_labels[actual_idx],
                    key=button_key,
                    use_container_width=True,
                    type=button_type,
                ):
                    st.session_state[selected_key] = actual_idx
                    selected_choice = actual_idx
                st.markdown("</div>", unsafe_allow_html=True)
    st.caption("1ã€œ4ã‚­ãƒ¼ã§é¸æŠè‚¢ã‚’å³ç­”ã§ãã¾ã™ã€‚E:è§£èª¬ F:ãƒ•ãƒ©ã‚° N/P:ç§»å‹• H:ãƒ˜ãƒ«ãƒ— R:SRSãƒªã‚»ãƒƒãƒˆ")
    confidence_value = st.session_state.get(confidence_key)
    if confidence_value is None:
        confidence_value = 50
    else:
        confidence_value = int(confidence_value)
    confidence_value = st.slider(
        "ç¢ºä¿¡åº¦ï¼ˆãœã‚“ãœã‚“è‡ªä¿¡ãªã— â†” å®Œç’§ï¼‰",
        0,
        100,
        value=confidence_value,
        key=confidence_key,
    )
    show_explanation = st.session_state.get(explanation_key, False)
    flagged = row["id"] in set(st.session_state.get("review_flags", []))
    grade_label = "æ¡ç‚¹"
    explanation_label = "è§£èª¬ã‚’éš ã™" if show_explanation else "è§£èª¬ã‚’è¡¨ç¤º"
    flag_label = "ãƒ•ãƒ©ã‚°è§£é™¤" if flagged else "å¾©ç¿’ãƒ•ãƒ©ã‚°"
    help_label = "ãƒ˜ãƒ«ãƒ—"
    auto_advance_enabled = st.session_state["settings"].get("auto_advance", False)
    action_cols = st.columns(5)
    with action_cols[0]:
        grade_clicked = st.button(
            grade_label,
            key=f"{key_prefix}_grade_{row['id']}",
            use_container_width=True,
            type="primary",
        )
    with action_cols[1]:
        if st.button(
            explanation_label,
            key=f"{key_prefix}_toggle_explanation_{row['id']}",
            use_container_width=True,
        ):
            show_explanation = not show_explanation
            st.session_state[explanation_key] = show_explanation
    with action_cols[2]:
        if st.button(
            flag_label,
            key=f"{key_prefix}_flag_{row['id']}",
            use_container_width=True,
        ):
            flags = set(st.session_state.get("review_flags", []))
            if flagged:
                flags.discard(row["id"])
            else:
                flags.add(row["id"])
            st.session_state["review_flags"] = list(flags)
            flagged = row["id"] in flags
    with action_cols[3]:
        help_visible = st.session_state.get(help_state_key, False)
        if st.button(
            help_label,
            key=f"{key_prefix}_help_{row['id']}",
            use_container_width=True,
        ):
            help_visible = not help_visible
            st.session_state[help_state_key] = help_visible
        else:
            help_visible = st.session_state.get(help_state_key, False)
    with action_cols[4]:
        if st.button(
            "SRSãƒªã‚»ãƒƒãƒˆ",
            key=f"{key_prefix}_srs_reset_{row['id']}",
            use_container_width=True,
        ):
            db.upsert_srs(
                row["id"],
                {
                    "repetition": 0,
                    "interval": 1,
                    "ease": st.session_state["settings"].get("sm2_initial_ease", 2.5),
                    "due_date": dt.date.today(),
                    "last_grade": None,
                    "updated_at": dt.datetime.now(),
                },
            )
            st.success("SRSã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚æ˜æ—¥ã‹ã‚‰å¾©ç¿’ã«å†æŠ•å…¥ã•ã‚Œã¾ã™ã€‚")
    if auto_advance_enabled and navigation and navigation.has_next:
        st.caption("æ¡ç‚¹å¾Œ0.8ç§’ã§æ¬¡å•ã«è‡ªå‹•é·ç§»ã—ã¾ã™ã€‚")
    if flagged:
        st.caption("ã“ã®å•é¡Œã¯å¾©ç¿’ãƒ•ãƒ©ã‚°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚")
    feedback = st.session_state.get(feedback_key)
    if grade_clicked:
        if selected_choice is None:
            st.warning("é¸æŠè‚¢ã‚’é¸ã‚“ã§ã‹ã‚‰æ¡ç‚¹ã—ã¦ãã ã•ã„ã€‚")
        else:
            correct_choice = row.get("correct")
            if pd.isna(correct_choice):
                st.warning("æ­£ç­”ãŒæœªç™»éŒ²ã®å•é¡Œã§ã™ã€‚è§£ç­”ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã‚“ã§ãã ã•ã„ã€‚")
            else:
                correct_choice = int(correct_choice)
                is_correct = (selected_choice + 1) == correct_choice
                initial_ease = st.session_state["settings"].get("sm2_initial_ease", 2.5)
                srs_row = db.fetch_srs(row["id"])
                grade_value = confidence_to_grade(is_correct, confidence_value)
                payload = sm2_update(srs_row, grade=grade_value, initial_ease=initial_ease)
                db.upsert_srs(row["id"], payload)
                log_offline_attempt(
                    {
                        "timestamp": dt.datetime.now().isoformat(),
                        "question_id": row["id"],
                        "year": row.get("year"),
                        "q_no": row.get("q_no"),
                        "category": row.get("category"),
                        "topic": row.get("topic"),
                        "selected": selected_choice + 1,
                        "correct": correct_choice,
                        "is_correct": is_correct,
                        "mode": attempt_mode,
                        "confidence": confidence_value,
                        "srs_grade": grade_value,
                    }
                )
                st.session_state[feedback_key] = {
                    "is_correct": is_correct,
                    "correct_choice": correct_choice,
                    "question_id": row["id"],
                    "confidence": confidence_value,
                    "grade": grade_value,
                }
                feedback = st.session_state[feedback_key]
                db.record_attempt(
                    row["id"],
                    selected_choice + 1,
                    is_correct,
                    seconds=0,
                    mode=attempt_mode,
                    confidence=confidence_value,
                    grade=grade_value,
                )
                if (
                    auto_advance_enabled
                    and navigation is not None
                    and navigation.has_next
                    and navigation.on_next is not None
                ):
                    time.sleep(0.8)
                    navigation.on_next()
                    st.experimental_rerun()
    if feedback and feedback.get("question_id") == row["id"]:
        correct_msg = choice_labels[feedback["correct_choice"] - 1]
        message = "æ­£è§£ã§ã™ï¼" if feedback["is_correct"] else f"ä¸æ­£è§£ã€‚æ­£ç­”ã¯ {correct_msg}"
        (st.success if feedback["is_correct"] else st.error)(message)
        st.caption(
            f"ç¢ºä¿¡åº¦ {feedback.get('confidence', confidence_value)}% â†’ å¾©ç¿’ã‚°ãƒ¬ãƒ¼ãƒ‰ {feedback.get('grade', '')}"
        )
    if show_explanation:
        st.markdown("#### è§£èª¬")
        render_explanation_content(row)
    if help_visible:
        st.info(
            """ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆä¸€è¦§\n- 1ã€œ4: é¸æŠè‚¢ã‚’é¸ã¶\n- E: è§£èª¬ã®è¡¨ç¤º/éè¡¨ç¤º\n- F: å¾©ç¿’ãƒ•ãƒ©ã‚°ã®åˆ‡ã‚Šæ›¿ãˆ\n- N/P: æ¬¡ã¸ãƒ»å‰ã¸\n- H: ã“ã®ãƒ˜ãƒ«ãƒ—"""
        )
    nav_prev_label = "å‰ã¸"
    nav_next_label = "æ¬¡ã¸"
    if navigation:
        nav_cols = st.columns([1, 1, 2])
        prev_kwargs = {
            "use_container_width": True,
            "disabled": not navigation.has_prev,
            "key": f"{key_prefix}_prev_{row['id']}",
        }
        next_kwargs = {
            "use_container_width": True,
            "disabled": not navigation.has_next,
            "key": f"{key_prefix}_next_{row['id']}",
        }
        if navigation.on_prev:
            prev_kwargs["on_click"] = navigation.on_prev
        if navigation.on_next:
            next_kwargs["on_click"] = navigation.on_next
        with nav_cols[0]:
            st.button(nav_prev_label, **prev_kwargs)
        with nav_cols[1]:
            st.button(nav_next_label, **next_kwargs)
        with nav_cols[2]:
            if navigation.label:
                st.caption(navigation.label)
    render_offline_downloads(f"{key_prefix}_{row['id']}")
    shortcut_map: Dict[str, str] = {}
    for idx, label in enumerate(button_labels[:4]):
        shortcut_map[str(idx + 1)] = label
    shortcut_map["e"] = explanation_label
    shortcut_map["f"] = flag_label
    shortcut_map["h"] = help_label
    shortcut_map["r"] = "SRSãƒªã‚»ãƒƒãƒˆ"
    if navigation:
        shortcut_map["n"] = nav_next_label
        shortcut_map["p"] = nav_prev_label
    register_keyboard_shortcuts(shortcut_map)

def format_question_label(df: pd.DataFrame, question_id: str) -> str:
    row = df[df["id"] == question_id].iloc[0]
    return f"{row['year']}å¹´ å•{row['q_no']} ({row['category']})"


def render_law_reference(row: pd.Series) -> None:
    query_source = row.get("tags") or row.get("topic") or row.get("category")
    if query_source:
        query = quote_plus(str(query_source).split(";")[0])
        url = LAW_REFERENCE_BASE_URL.format(query=query)
        st.caption(f"{LAW_BASELINE_LABEL} ï½œ [æ¡æ–‡æ¤œç´¢]({url})")
    else:
        st.caption(LAW_BASELINE_LABEL)


def render_mock_exam(db: DBManager, df: pd.DataFrame) -> None:
    st.title("æ¨¡è©¦")
    if df.empty:
        st.warning("è¨­å•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    with st.form("mock_exam_form"):
        year_mode = st.selectbox(
            "å‡ºé¡Œæ–¹å¼",
            ["æœ€æ–°å¹´åº¦", "å¹´åº¦é¸æŠ", "å±¤åŒ–ãƒ©ãƒ³ãƒ€ãƒ 50"],
            help="æœ€æ–°å¹´åº¦ã®å…¨å•ã€ä»»æ„å¹´åº¦ã®ã¿ã€ã¾ãŸã¯åˆ†é‡ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã£ãŸ50å•ã‹ã‚‰é¸ã¹ã¾ã™ã€‚",
        )
        if year_mode == "å¹´åº¦é¸æŠ":
            selected_year = st.selectbox(
                "å¹´åº¦",
                sorted(df["year"].unique(), reverse=True),
                help="æ¨¡è©¦ã«ä½¿ç”¨ã™ã‚‹å¹´åº¦ã‚’é¸æŠã—ã¾ã™ã€‚",
            )
            subset = df[df["year"] == selected_year]
            questions = list(subset["id"])
        elif year_mode == "æœ€æ–°å¹´åº¦":
            latest_year = df["year"].max()
            subset = df[df["year"] == latest_year]
            questions = list(subset["id"])
        else:
            questions = stratified_exam(df)
        submit = st.form_submit_button("æ¨¡è©¦é–‹å§‹", help="é¸æŠã—ãŸæ¡ä»¶ã§æ¨¡è©¦ã‚’é–‹å§‹ã—ã€å³åº§ã«è©¦é¨“ç”»é¢ã¸ç§»å‹•ã—ã¾ã™ã€‚")
    if submit:
        st.session_state.pop("exam_result_æ¨¡è©¦", None)
        st.session_state["exam_session"] = ExamSession(
            id=None,
            name=f"æ¨¡è©¦ {dt.datetime.now():%Y%m%d-%H%M}",
            questions=questions,
            started_at=dt.datetime.now(),
            year_mode=year_mode,
            mode="æ¨¡è©¦",
        )
    session: Optional[ExamSession] = st.session_state.get("exam_session")
    if session and session.mode == "æ¨¡è©¦":
        render_exam_session_body(db, df, session, key_prefix="mock")
    result = st.session_state.get("exam_result_æ¨¡è©¦")
    if result:
        display_exam_result(result)


def render_srs(db: DBManager) -> None:
    st.title("å¼±ç‚¹å¾©ç¿’")
    due_df = db.get_due_srs()
    if due_df.empty:
        st.info("ä»Šæ—¥å¾©ç¿’ã™ã¹ãå•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    for _, row in due_df.iterrows():
        st.markdown(f"### {row['question'][:40]}...")
        st.write(f"åˆ†é‡: {row['category']} / æœŸé™: {row['due_date']}")
        grade = st.slider(
            f"è©•ä¾¡ ({row['question_id']})",
            0,
            5,
            3,
            help="5=å®Œå…¨ã«è¦šãˆãŸã€0=å…¨ãè¦šãˆã¦ã„ãªã„ã€‚è©•ä¾¡ã«å¿œã˜ã¦æ¬¡å›å¾©ç¿’æ—¥ãŒå¤‰ã‚ã‚Šã¾ã™ã€‚",
        )
        if st.button(
            "è©•ä¾¡ã‚’ä¿å­˜",
            key=f"srs_save_{row['question_id']}",
            help="SM-2ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ãæ¬¡å›ã®å‡ºé¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æ›´æ–°ã—ã¾ã™ã€‚",
        ):
            initial_ease = st.session_state["settings"].get("sm2_initial_ease", 2.5)
            payload = sm2_update(row, grade, initial_ease=initial_ease)
            db.upsert_srs(row["question_id"], payload)
            st.success("SRSã‚’æ›´æ–°ã—ã¾ã—ãŸ")


def render_stats(db: DBManager, df: pd.DataFrame) -> None:
    st.title("åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    attempts = db.get_attempt_stats()
    if attempts.empty:
        st.info("çµ±è¨ˆæƒ…å ±ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã—ã‚‡ã†ã€‚")
        return
    try:
        attempts["created_at"] = pd.to_datetime(attempts["created_at"])
        attempts["seconds"] = pd.to_numeric(attempts.get("seconds"), errors="coerce")
        attempts["confidence"] = pd.to_numeric(attempts.get("confidence"), errors="coerce")
    except Exception as exc:
        st.error(f"å­¦ç¿’å±¥æ­´ã®æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})")
        st.info("CSVã‚’ç›´æ¥ç·¨é›†ã—ãŸå ´åˆã¯ã€æ—¥ä»˜ã‚„ç§’æ•°ã®åˆ—ãŒæ•°å€¤ãƒ»æ—¥æ™‚å½¢å¼ã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    question_meta_cols = ["id", "question", "category", "topic", "tags", "difficulty"]
    merged = attempts.merge(
        df[question_meta_cols],
        left_on="question_id",
        right_on="id",
        how="left",
        suffixes=("", "_question"),
    )
    for col in ["category", "topic"]:
        alt_col = f"{col}_question"
        if alt_col in merged.columns:
            if col in merged.columns:
                merged[col] = merged[col].fillna(merged[alt_col])
            else:
                merged[col] = merged[alt_col]
            merged = merged.drop(columns=[alt_col])
    if merged.empty:
        st.warning("é›†è¨ˆå¯¾è±¡ã®è¨­å•ãŒç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚è¨­å•ãƒ‡ãƒ¼ã‚¿ãŒå‰Šé™¤ã•ã‚Œã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.info("ã€ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã§questions.csvã‚’å†åº¦å–ã‚Šè¾¼ã¿ã€è¨­å•IDã¨å­¦ç¿’å±¥æ­´ã®å¯¾å¿œã‚’å¾©å…ƒã§ãã¾ã™ã€‚")
        return
    accuracy_series = merged["is_correct"].dropna()
    seconds_series = merged["seconds"].dropna()
    confidence_series = merged["confidence"].dropna()
    accuracy = accuracy_series.mean() if not accuracy_series.empty else np.nan
    avg_seconds = seconds_series.mean() if not seconds_series.empty else np.nan
    avg_confidence = confidence_series.mean() if not confidence_series.empty else np.nan
    st.subheader("ã‚µãƒãƒªãƒ¼")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æŒ‘æˆ¦å›æ•°", f"{len(merged)} å›")
    with col2:
        accuracy_text = f"{accuracy * 100:.1f}%" if not np.isnan(accuracy) else "--"
        st.metric("å¹³å‡æ­£ç­”ç‡", accuracy_text)
    with col3:
        st.metric("å¹³å‡è§£ç­”æ™‚é–“", f"{avg_seconds:.1f} ç§’" if not np.isnan(avg_seconds) else "--")
    if not np.isnan(avg_confidence):
        st.caption(f"å¹³å‡ç¢ºä¿¡åº¦: {avg_confidence:.1f}%")
    else:
        st.caption("å¹³å‡ç¢ºä¿¡åº¦: -- (ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“)")

    import altair as alt

    st.subheader("åˆ†é‡åˆ¥åˆ†æ")
    category_stats = (
        merged.groupby("category")
        .agg(
            accuracy=("is_correct", "mean"),
            avg_seconds=("seconds", "mean"),
            attempts_count=("is_correct", "count"),
        )
        .reset_index()
    )
    if category_stats.empty:
        st.info("åˆ†é‡æƒ…å ±ã®ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚questions.csv ã® category åˆ—ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        try:
            accuracy_chart = (
                alt.Chart(category_stats)
                .mark_bar()
                .encode(
                    x=alt.X("category", title="åˆ†é‡"),
                    y=alt.Y("accuracy", title="æ­£ç­”ç‡", axis=alt.Axis(format="%")),
                    tooltip=["category", alt.Tooltip("accuracy", format=".2%"), "attempts_count"],
                )
                .properties(height=320)
            )
            st.altair_chart(accuracy_chart, use_container_width=True)
        except Exception as exc:
            st.warning(f"åˆ†é‡åˆ¥æ­£ç­”ç‡ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({exc})")
            st.caption("ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒé›†ã¾ã‚‹ã¨è‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
        try:
            time_chart = (
                alt.Chart(category_stats)
                .mark_line(point=True)
                .encode(
                    x=alt.X("category", title="åˆ†é‡"),
                    y=alt.Y("avg_seconds", title="å¹³å‡è§£ç­”æ™‚é–“ (ç§’)", scale=alt.Scale(zero=False)),
                    tooltip=["category", alt.Tooltip("avg_seconds", format=".1f"), "attempts_count"],
                )
            )
            st.altair_chart(time_chart, use_container_width=True)
        except Exception as exc:
            st.warning(f"åˆ†é‡åˆ¥æ™‚é–“ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({exc})")
            st.caption("ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒé›†ã¾ã‚‹ã¨è‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    st.subheader("ç¢ºä¿¡åº¦ã¨æ­£ç­”ã®ç›¸é–¢")
    valid_conf = merged.dropna(subset=["confidence"])
    if valid_conf.empty:
        st.info("ç¢ºä¿¡åº¦ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ååˆ†ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’æ™‚ã«ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§è‡ªå·±è©•ä¾¡ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
    else:
        corr = valid_conf["confidence"].corr(valid_conf["is_correct"])
        st.metric("ç›¸é–¢ä¿‚æ•°", f"{corr:.2f}")
        try:
            scatter = (
                alt.Chart(valid_conf)
                .mark_circle(opacity=0.6)
                .encode(
                    x=alt.X("confidence", title="ç¢ºä¿¡åº¦ (%)"),
                    y=alt.Y("is_correct", title="æ­£ç­” (1=æ­£è§£)", scale=alt.Scale(domain=[-0.1, 1.1])),
                    color=alt.Color("category", legend=None),
                    tooltip=["category", "topic", "confidence", "is_correct", "seconds"],
                )
            )
            st.altair_chart(scatter, use_container_width=True)
        except Exception as exc:
            st.warning(f"ç›¸é–¢æ•£å¸ƒå›³ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({exc})")
            st.caption("ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒé›†ã¾ã‚‹ã¨è‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    st.subheader("ã²ã£ã‹ã‘èªå½™ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
    heatmap_df = compute_tricky_vocab_heatmap(merged, df)
    if heatmap_df.empty:
        st.info("èª¤ç­”èªå½™ã®ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        try:
            word_order = (
                heatmap_df.groupby("word")["count"].sum().sort_values(ascending=False).index.tolist()
            )
            heatmap = (
                alt.Chart(heatmap_df)
                .mark_rect()
                .encode(
                    x=alt.X("category", title="åˆ†é‡"),
                    y=alt.Y("word", title="èªå½™", sort=word_order),
                    color=alt.Color("count", title="èª¤ç­”å›æ•°", scale=alt.Scale(scheme="reds")),
                    tooltip=["word", "category", "count"],
                )
            )
            st.altair_chart(heatmap, use_container_width=True)
        except Exception as exc:
            st.warning(f"èªå½™ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({exc})")
            st.caption("ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒé›†ã¾ã‚‹ã¨è‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    st.subheader("æœ€ã‚‚æ”¹å–„ã—ãŸè«–ç‚¹")
    improvement = compute_most_improved_topic(merged, df)
    if improvement:
        st.success(
            f"{improvement['topic']}ï¼šæ­£ç­”ç‡ãŒ {(improvement['early'] * 100):.1f}% â†’ {(improvement['late'] * 100):.1f}% (ï¼‹{improvement['delta'] * 100:.1f}ãƒã‚¤ãƒ³ãƒˆ)"
        )
    else:
        st.info("æ”¹å–„ã®å‚¾å‘ã‚’ç¤ºã™è«–ç‚¹ã¯ã¾ã æ¤œå‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç¶™ç¶šã—ã¦å­¦ç¿’ã—ã¾ã—ã‚‡ã†ã€‚")
def render_data_io(db: DBManager) -> None:
    st.title("ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›")
    timestamp = dt.datetime.now().strftime("%Y%m%d-%H%M%S")
    st.markdown("### ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«")
    st.download_button(
        "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ZIP)",
        data=get_template_archive(),
        file_name=f"takken_templates_{timestamp}.zip",
        mime="application/zip",
    )
    st.caption("è¨­å•ãƒ»æ­£ç­”ãƒ‡ãƒ¼ã‚¿ã®CSV/XLSXãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒå«ã¾ã‚Œã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ç·¨é›†ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚")
    sample_cols = st.columns(2)
    with sample_cols[0]:
        st.download_button(
            "ã‚µãƒ³ãƒ—ãƒ« questions.csv",
            data=build_sample_questions_csv(),
            file_name="sample_questions.csv",
            mime="text/csv",
            help="Excelã§é–‹ã„ã¦å€¤ã‚’ä¸Šæ›¸ãã™ã‚Œã°ã€ãã®ã¾ã¾å–ã‚Šè¾¼ã¿ã§ãã¾ã™ã€‚",
        )
    with sample_cols[1]:
        st.download_button(
            "ã‚µãƒ³ãƒ—ãƒ« answers.csv",
            data=build_sample_answers_csv(),
            file_name="sample_answers.csv",
            mime="text/csv",
            help="æ­£ç­”ç•ªå·ã‚„è§£èª¬ã®è¨˜å…¥ä¾‹ã§ã™ã€‚ã‚³ãƒ”ãƒ¼ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚",
        )
    st.caption("ã‚µãƒ³ãƒ—ãƒ«CSVã¯Excelã«è²¼ã‚Šä»˜ã‘ã¦ä½¿ãˆã‚‹ã‚ˆã†åˆ—å¹…ã‚’èª¿æ•´æ¸ˆã¿ã§ã™ã€‚ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆã§æ‰‹æ—©ãç™»éŒ²ã§ãã¾ã™ã€‚")
    st.markdown("### ã‚¯ã‚¤ãƒƒã‚¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (questions.csv / answers.csv)")
    quick_cols = st.columns(2)
    with quick_cols[0]:
        quick_questions_file = st.file_uploader(
            "questions.csv ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["csv"],
            key="quick_questions_file",
        )
    with quick_cols[1]:
        quick_answers_file = st.file_uploader(
            "answers.csv ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["csv"],
            key="quick_answers_file",
        )
    if st.button("ã‚¯ã‚¤ãƒƒã‚¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ", key="quick_import_button"):
        quick_errors: List[str] = []
        questions_df: Optional[pd.DataFrame] = None
        answers_df: Optional[pd.DataFrame] = None
        if quick_questions_file is None and quick_answers_file is None:
            st.warning("questions.csv ã‹ answers.csv ã®ã„ãšã‚Œã‹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            if quick_questions_file is not None:
                data = quick_questions_file.getvalue()
                try:
                    questions_df = pd.read_csv(io.BytesIO(data))
                except UnicodeDecodeError:
                    questions_df = pd.read_csv(io.BytesIO(data), encoding="cp932")
                quick_errors.extend(validate_question_records(questions_df))
            if quick_answers_file is not None:
                data = quick_answers_file.getvalue()
                try:
                    answers_df = pd.read_csv(io.BytesIO(data))
                except UnicodeDecodeError:
                    answers_df = pd.read_csv(io.BytesIO(data), encoding="cp932")
                quick_errors.extend(validate_answer_records(answers_df))
            if quick_errors:
                for err in quick_errors:
                    st.error(err)
                st.info("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®åˆ—æ§‹æˆã¨çªåˆã—ã¦ãã ã•ã„ã€‚ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ã‹ã‚‰æœ€æ–°ã®CSVã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—ã§ãã¾ã™ã€‚")
            else:
                policy = {"explanation": "overwrite", "tags": "merge"}
                merged_df: Optional[pd.DataFrame] = None
                rejects_q = pd.DataFrame()
                rejects_a = pd.DataFrame()
                conflicts = pd.DataFrame()
                normalization_failed = False
                if questions_df is not None:
                    try:
                        normalized_q = normalize_questions(questions_df)
                    except Exception as exc:
                        st.error(f"questions.csv ã®æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
                        normalization_failed = True
                        normalized_q = None
                else:
                    normalized_q = None
                if answers_df is not None:
                    try:
                        normalized_a = normalize_answers(answers_df)
                    except Exception as exc:
                        st.error(f"answers.csv ã®æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
                        normalization_failed = True
                        normalized_a = None
                else:
                    normalized_a = None
                if normalization_failed:
                    st.warning("åˆ—åã‚„å€¤ã®å½¢å¼ã‚’è¦‹ç›´ã—ã¦ã‹ã‚‰å†åº¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚")
                else:
                    if normalized_q is not None and normalized_a is not None:
                        merged_df, rejects_q, rejects_a, conflicts = merge_questions_answers(
                            normalized_q, normalized_a, policy=policy
                        )
                    elif normalized_q is not None:
                        merged_df = normalized_q
                    elif normalized_a is not None:
                        existing = load_questions_df()
                        if existing.empty:
                            st.error("è¨­å•ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚answers.csv ã‚’å–ã‚Šè¾¼ã‚€å‰ã« questions.csv ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
                        else:
                            merged_df, rejects_q, rejects_a, conflicts = merge_questions_answers(
                                existing, normalized_a, policy=policy
                            )
                    if merged_df is not None:
                        inserted, updated = db.upsert_questions(merged_df)
                        rebuild_tfidf_cache()
                        st.success(f"ã‚¯ã‚¤ãƒƒã‚¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚è¿½åŠ  {inserted} ä»¶ / æ›´æ–° {updated} ä»¶")
                        if not rejects_q.empty or not rejects_a.empty:
                            st.warning(
                                f"å–ã‚Šè¾¼ã‚ãªã‹ã£ãŸãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚questions: {len(rejects_q)} ä»¶ / answers: {len(rejects_a)} ä»¶"
                            )
                            with st.expander("å–ã‚Šè¾¼ã‚ãªã‹ã£ãŸè¡Œã®è©³ç´°", expanded=False):
                                if not rejects_q.empty:
                                    st.markdown("**questions.csv**")
                                    st.dataframe(rejects_q.head(20))
                                if not rejects_a.empty:
                                    st.markdown("**answers.csv**")
                                    st.dataframe(rejects_a.head(20))
                                st.caption("ç†ç”±åˆ—ã‚’å‚è€ƒã«CSVã®è©²å½“è¡Œã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚å…¨ä»¶ã¯rejects_*.csvã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
                        if not conflicts.empty:
                            st.info(f"æ­£ç­”ã®è¡çªãŒ {len(conflicts)} ä»¶ã‚ã‚Šã€ä¸Šæ›¸ãã—ã¾ã—ãŸã€‚")
    st.markdown("### ã‚¯ã‚¤ãƒƒã‚¯ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ (questions.csv / answers.csv)")
    existing_questions = load_questions_df()
    if existing_questions.empty:
        st.info("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯èƒ½ãªè¨­å•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        question_cols = QUESTION_TEMPLATE_COLUMNS.copy()
        if "id" in existing_questions.columns and "id" not in question_cols:
            question_cols.append("id")
        q_export = existing_questions[question_cols]
        q_buffer = io.StringIO()
        q_export.to_csv(q_buffer, index=False)
        st.download_button(
            "questions.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            q_buffer.getvalue(),
            file_name="questions.csv",
            mime="text/csv",
            key="export_questions_csv",
        )
        answers_export = build_answers_export(existing_questions)
        a_buffer = io.StringIO()
        answers_export.to_csv(a_buffer, index=False)
        st.download_button(
            "answers.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            a_buffer.getvalue(),
            file_name="answers.csv",
            mime="text/csv",
            key="export_answers_csv",
        )
    st.markdown("### (1) ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ")
    uploaded_files = st.file_uploader(
        "è¨­å•ãƒ»è§£ç­”ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ (CSV/XLSX/ZIP)",
        type=["csv", "xlsx", "xls", "zip"],
        accept_multiple_files=True,
    )
    datasets = []
    if uploaded_files:
        for file in uploaded_files:
            try:
                store_uploaded_file(file, timestamp)
                for name, df in decode_uploaded_file(file):
                    kind = guess_dataset_kind(df)
                    datasets.append({"name": name, "data": df, "kind": kind})
            except Exception as e:
                st.error(f"{file.name}: èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})")
    if not datasets:
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    st.markdown("### (2) ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ & ãƒãƒƒãƒ”ãƒ³ã‚°")
    mapping_profiles = db.fetch_mapping_profiles()
    profile_options = ["æ–°è¦ãƒãƒƒãƒ”ãƒ³ã‚°"] + (mapping_profiles["name"].tolist() if not mapping_profiles.empty else [])
    selected_profile = st.selectbox("ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ", profile_options)
    profile_mapping: Dict[str, Dict[str, str]] = {}
    if selected_profile != "æ–°è¦ãƒãƒƒãƒ”ãƒ³ã‚°" and not mapping_profiles.empty:
        profile_row = mapping_profiles[mapping_profiles["name"] == selected_profile].iloc[0]
        mapping_data = profile_row["mapping_json"]
        if isinstance(mapping_data, str):
            try:
                profile_mapping = json.loads(mapping_data)
            except json.JSONDecodeError:
                profile_mapping = {}
        else:
            profile_mapping = mapping_data

    normalized_question_frames = []
    normalized_answer_frames = []
    conflict_resolutions: List[Dict[str, object]] = []

    policy = {
        "explanation": st.selectbox("è§£èª¬ã®å–ã‚Šæ‰±ã„", ["overwrite", "append"], format_func=lambda x: "ä¸Šæ›¸ã" if x == "overwrite" else "è¿½è¨˜"),
        "tags": st.selectbox("ã‚¿ã‚°ã®å–ã‚Šæ‰±ã„", ["merge", "overwrite"], format_func=lambda x: "çµåˆ" if x == "merge" else "ä¸Šæ›¸ã"),
    }

    for dataset in datasets:
        df = dataset["data"]
        st.subheader(dataset["name"])
        st.dataframe(df.head())
        kind = st.selectbox(
            f"ç¨®åˆ¥ ({dataset['name']})",
            [MAPPING_KIND_QUESTIONS, MAPPING_KIND_ANSWERS],
            index=0 if dataset["kind"] == MAPPING_KIND_QUESTIONS else 1,
        )
        dataset["kind"] = kind
        columns = df.columns.tolist()
        lower_map = {col.lower(): col for col in columns}
        if kind == MAPPING_KIND_QUESTIONS:
            mapping_targets = {
                "year": "å¹´åº¦",
                "q_no": "å•ç•ª",
                "category": "å¤§åˆ†é¡",
                "topic": "å°åˆ†é¡",
                "question": "å•é¡Œæ–‡",
                "choice1": "é¸æŠè‚¢1",
                "choice2": "é¸æŠè‚¢2",
                "choice3": "é¸æŠè‚¢3",
                "choice4": "é¸æŠè‚¢4",
                "explanation": "è§£èª¬",
                "difficulty": "é›£æ˜“åº¦",
                "tags": "ã‚¿ã‚°",
                "id": "ID",
            }
        else:
            mapping_targets = {
                "year": "å¹´åº¦",
                "q_no": "å•ç•ª",
                "correct_number": "æ­£ç­”ç•ªå·",
                "correct_label": "æ­£ç­”ãƒ©ãƒ™ãƒ«",
                "correct_text": "æ­£ç­”ãƒ†ã‚­ã‚¹ãƒˆ",
                "explanation": "è§£èª¬",
                "difficulty": "é›£æ˜“åº¦",
                "tags": "ã‚¿ã‚°",
            }
        saved_mapping = profile_mapping.get(dataset["name"], {}) if profile_mapping else {}
        mapping = {}
        for key, label in mapping_targets.items():
            default_idx = -1
            if saved_mapping and key in saved_mapping and saved_mapping[key] in columns:
                default_idx = columns.index(saved_mapping[key])
            elif key in lower_map:
                default_idx = columns.index(lower_map[key])
            selected_col = st.selectbox(
                f"{label}",
                ["æœªè¨­å®š"] + columns,
                index=default_idx + 1 if default_idx >= 0 else 0,
                key=f"map_{dataset['name']}_{key}",
            )
            if selected_col != "æœªè¨­å®š":
                mapping[key] = selected_col
        try:
            if kind == MAPPING_KIND_QUESTIONS:
                normalized = normalize_questions(df, mapping=mapping)
                normalized_question_frames.append(normalized)
            else:
                normalized = normalize_answers(df, mapping=mapping)
                normalized_answer_frames.append(normalized)
            dataset["mapping"] = mapping
        except Exception as e:
            st.error(f"ãƒãƒƒãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")

    if st.checkbox("ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¿å­˜"):
        profile_name = st.text_input("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå")
        if profile_name and st.button("ä¿å­˜"):
            mapping_payload = {ds["name"]: ds.get("mapping", {}) for ds in datasets}
            db.save_mapping_profile(profile_name, "mixed", mapping_payload)
            st.success("ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ")

    if not normalized_question_frames:
        st.warning("è¨­å•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    merged_questions = pd.concat(normalized_question_frames).drop_duplicates(subset=["id"])
    merged_answers = pd.concat(normalized_answer_frames) if normalized_answer_frames else pd.DataFrame()

    if not merged_answers.empty:
        merged, rejects_q, rejects_a, conflicts = merge_questions_answers(merged_questions, merged_answers, policy)
    else:
        merged = merged_questions
        rejects_q = pd.DataFrame()
        rejects_a = pd.DataFrame()
        conflicts = pd.DataFrame()

    if not conflicts.empty:
        st.error("æ­£ç­”æƒ…å ±ã®ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãŒã‚ã‚Šã¾ã™ã€‚è§£æ±ºæ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        with st.form("conflict_resolution_form"):
            for _, conflict in conflicts.iterrows():
                st.write(f"{int(conflict['year'])}å¹´ å•{int(conflict['q_no'])}")
                action = st.selectbox(
                    f"å‡¦ç†æ–¹æ³• ({conflict['id']})",
                    ["æ—¢å­˜ã‚’ç¶­æŒ", "è§£ç­”ã§ä¸Šæ›¸ã", "æ‰‹å‹•ä¿®æ­£"],
                    key=f"conflict_action_{conflict['id']}",
                )
                manual_value = st.number_input(
                    f"æ‰‹å‹•æ­£ç­”ç•ªå· ({conflict['id']})",
                    min_value=1,
                    max_value=4,
                    value=int(conflict["existing"]) if pd.notna(conflict["existing"]) and int(conflict["existing"]) in [1, 2, 3, 4] else 1,
                    key=f"conflict_manual_{conflict['id']}",
                )
                conflict_resolutions.append(
                    {
                        "id": conflict["id"],
                        "action": action,
                        "manual": manual_value,
                        "incoming": conflict["incoming"],
                        "existing": conflict["existing"],
                    }
                )
            applied = st.form_submit_button("è§£æ±ºã‚’é©ç”¨")
        if not applied:
            st.stop()
        for resolution in conflict_resolutions:
            if resolution["action"] == "è§£ç­”ã§ä¸Šæ›¸ã":
                merged.loc[merged["id"] == resolution["id"], "correct"] = resolution["incoming"]
            elif resolution["action"] == "æ‰‹å‹•ä¿®æ­£":
                merged.loc[merged["id"] == resolution["id"], "correct"] = resolution["manual"]
        conflicts = pd.DataFrame()

    st.markdown("### (3) æ­£è¦åŒ– & ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœ")
    st.success(f"è¨­å•{len(merged)}ä»¶ã‚’å–ã‚Šè¾¼ã¿ã¾ã™ã€‚")
    if not rejects_a.empty:
        buffer = io.StringIO()
        rejects_a.to_csv(buffer, index=False)
        st.download_button("rejects_answers.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buffer.getvalue(), file_name="rejects_answers.csv", mime="text/csv")
    if not rejects_q.empty:
        buffer = io.StringIO()
        rejects_q.to_csv(buffer, index=False)
        st.download_button("rejects_questions.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buffer.getvalue(), file_name="rejects_questions.csv", mime="text/csv")

    if st.button("(4) çµ±åˆ (UPSERT) å®Ÿè¡Œ"):
        started = dt.datetime.now()
        progress = st.progress(0)
        inserted, updated = db.upsert_questions(merged)
        progress.progress(70)
        finished = dt.datetime.now()
        seconds = (finished - started).total_seconds()
        policy_payload = {**policy, "conflict_resolutions": conflict_resolutions}
        db.log_import(
            {
                "started_at": started,
                "finished_at": finished,
                "files": len(uploaded_files),
                "inserted": inserted,
                "updated": updated,
                "rejected": len(rejects_a) + len(rejects_q),
                "conflicts": len(conflicts),
                "seconds": seconds,
                "policy": json.dumps(policy_payload, ensure_ascii=False),
            }
        )
        rebuild_tfidf_cache()
        progress.progress(100)
        st.success("ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚TF-IDFã‚’å†æ§‹ç¯‰ã—ã¾ã—ãŸã€‚")

    st.markdown("### (5) å±¥æ­´ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    with db.engine.connect() as conn:
        attempts_df = pd.read_sql(select(attempts_table), conn)
        exams_df = pd.read_sql(select(exams_table), conn)
    if not attempts_df.empty:
        buffer = io.StringIO()
        attempts_df.to_csv(buffer, index=False)
        st.download_button("attempts.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buffer.getvalue(), file_name="attempts.csv", mime="text/csv")
    if not exams_df.empty:
        buffer = io.StringIO()
        exams_df.to_csv(buffer, index=False)
        st.download_button("exams.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buffer.getvalue(), file_name="exams.csv", mime="text/csv")
    if DB_PATH.exists():
        st.download_button("SQLiteãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", DB_PATH.read_bytes(), file_name="takken.db")

    st.markdown("### (6) ãƒ‡ãƒ¼ã‚¿æ¶ˆå»")
    with st.form("data_reset_form"):
        reset_attempts = st.checkbox("å­¦ç¿’å±¥æ­´ (attempts) ã‚’å‰Šé™¤")
        reset_exams = st.checkbox("æ¨¡è©¦çµæœ (exams) ã‚’å‰Šé™¤")
        reset_all = st.checkbox("å…¨ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ– (è¨­å•å«ã‚€)")
        confirmed = st.form_submit_button("å‰Šé™¤ã‚’å®Ÿè¡Œ")
    if confirmed:
        with db.engine.begin() as conn:
            if reset_all:
                for table in [attempts_table, exams_table, srs_table, questions_table]:
                    conn.execute(table.delete())
            else:
                if reset_attempts:
                    conn.execute(attempts_table.delete())
                if reset_exams:
                    conn.execute(exams_table.delete())
        rebuild_tfidf_cache()
        st.success("é¸æŠã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

    st.markdown("### (7) ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    with open(DATA_DIR / "questions_sample.csv", "rb") as f:
        st.download_button("è¨­å•ãƒ†ãƒ³ãƒ—ãƒ¬CSV", f, file_name="questions_template.csv")
    with open(DATA_DIR / "answers_sample.csv", "rb") as f:
        st.download_button("è§£ç­”ãƒ†ãƒ³ãƒ—ãƒ¬CSV", f, file_name="answers_template.csv")


def render_settings() -> None:
    st.title("è¨­å®š")
    settings = st.session_state["settings"]
    st.info("å­¦ç¿’ä½“é¨“ã‚’è‡ªåˆ†å¥½ã¿ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™ã€‚å„é …ç›®ã®èª¬æ˜ã‚’å‚è€ƒã«èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
    settings["theme"] = st.selectbox(
        "ãƒ†ãƒ¼ãƒ",
        ["ãƒ©ã‚¤ãƒˆ", "ãƒ€ãƒ¼ã‚¯"],
        index=0 if settings.get("theme") == "ãƒ©ã‚¤ãƒˆ" else 1,
        help="ç”»é¢ã®é…è‰²ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚æš—ã„ç’°å¢ƒã§ã¯ãƒ€ãƒ¼ã‚¯ãƒ†ãƒ¼ãƒãŒãŠã™ã™ã‚ã§ã™ã€‚",
    )
    size_options = list(FONT_SIZE_SCALE.keys())
    default_size = settings.get("font_size", "æ¨™æº–")
    size_index = size_options.index(default_size) if default_size in size_options else size_options.index("æ¨™æº–")
    settings["font_size"] = st.selectbox(
        "ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º",
        size_options,
        index=size_index,
        help="æ–‡å­—ã‚µã‚¤ã‚ºã‚’èª¿æ•´ã—ã¦èª­ã¿ã‚„ã™ã•ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚ã€å¤§ãã„ã€ã¯å¤œé–“å­¦ç¿’ã‚„é«˜è§£åƒåº¦ãƒ¢ãƒ‹ã‚¿å‘ãã§ã™ã€‚",
    )
    settings["shuffle_choices"] = st.checkbox(
        "é¸æŠè‚¢ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«",
        value=settings.get("shuffle_choices", True),
        help="æ¯å›é¸æŠè‚¢ã®é †ç•ªã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å…¥ã‚Œæ›¿ãˆã¦ã€ä½ç½®è¨˜æ†¶ã«é ¼ã‚‰ãªã„è¨“ç·´ã‚’è¡Œã„ã¾ã™ã€‚",
    )
    settings["timer"] = st.checkbox(
        "ã‚¿ã‚¤ãƒãƒ¼ã‚’è¡¨ç¤º",
        value=settings.get("timer", True),
        help="å›ç­”ç”»é¢ã«çµŒéæ™‚é–“ã‚’è¡¨ç¤ºã—ã¦æœ¬ç•ªåŒæ§˜ã®æ™‚é–“æ„Ÿè¦šã‚’é¤Šã„ã¾ã™ã€‚",
    )
    settings["sm2_initial_ease"] = st.slider(
        "SM-2åˆæœŸease",
        1.3,
        3.0,
        settings.get("sm2_initial_ease", 2.5),
        help="é–“éš”åå¾©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åˆæœŸé›£æ˜“åº¦ã§ã™ã€‚æ—¢å®šå€¤2.5ã§è¿·ã£ãŸã‚‰ãã®ã¾ã¾ã«ã—ã¾ã—ã‚‡ã†ã€‚",
    )
    settings["auto_advance"] = st.checkbox(
        "æ¡ç‚¹å¾Œã«è‡ªå‹•ã§æ¬¡å•ã¸é€²ã‚€ (0.8ç§’é…å»¶)",
        value=settings.get("auto_advance", False),
        help="æ­£èª¤åˆ¤å®šå¾Œã«å¾…æ©Ÿã›ãšæ¬¡ã®å•é¡Œã¸é€²ã¿ãŸã„å ´åˆã«æœ‰åŠ¹åŒ–ã—ã¾ã™ã€‚",
    )
    settings["review_low_confidence_threshold"] = st.slider(
        "ä½ç¢ºä¿¡ã¨ã—ã¦æ‰±ã†ç¢ºä¿¡åº¦ (%)",
        0,
        100,
        int(settings.get("review_low_confidence_threshold", 60)),
        help="è‡ªå·±è©•ä¾¡ã®ç¢ºä¿¡åº¦ãŒã“ã®å€¤æœªæº€ãªã‚‰å¾©ç¿’å¯¾è±¡ã«å«ã‚ã¾ã™ã€‚",
    )
    settings["review_elapsed_days"] = st.slider(
        "å¾©ç¿’æŠ½å‡ºã®çµŒéæ—¥æ•°ã—ãã„å€¤",
        1,
        30,
        int(settings.get("review_elapsed_days", 7)),
        help="æœ€çµ‚æŒ‘æˆ¦ã‹ã‚‰ã“ã®æ—¥æ•°ãŒçµŒéã—ãŸå•é¡Œã‚’å¾©ç¿’å€™è£œã«è¿½åŠ ã—ã¾ã™ã€‚",
    )
    if st.button("TF-IDFã‚’å†å­¦ç¿’", help="æ¤œç´¢ç²¾åº¦ãŒæ°—ã«ãªã‚‹ã¨ãã«å†è¨ˆç®—ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿æ›´æ–°å¾Œã®å†å®Ÿè¡ŒãŒãŠã™ã™ã‚ã§ã™ã€‚"):
        rebuild_tfidf_cache()
        st.success("TF-IDFã‚’å†å­¦ç¿’ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()
